# Название

- [Название](#название)
  - [Абстракт](#абстракт)
  - [Введение](#введение)
  - [Обзор литературы](#обзор-литературы)
  - [Определение области и цели проекта](#определение-области-и-цели-проекта)
  - [Сбор и подготовка данных](#сбор-и-подготовка-данных)
  - [Выбор технологии и архитектуры модели](#выбор-технологии-и-архитектуры-модели)
    - [Описание модели и её модификации](#описание-модели-и-её-модификации)
    - [Метрики валидации](#метрики-валидации)
      - [BLEU (Bilingual Evaluation Understudy)](#bleu-bilingual-evaluation-understudy)
      - [ROUGE (Recall-Oriented Understudy for Gisting Evaluation)](#rouge-recall-oriented-understudy-for-gisting-evaluation)
      - [METEOR (Metric for Evaluation of Translation with Explicit ORdering)](#meteor-metric-for-evaluation-of-translation-with-explicit-ordering)
    - [Генерация текста](#генерация-текста)
      - [Argmax](#argmax)
      - [Temperature Sampling](#temperature-sampling)
      - [Top-k Sampling](#top-k-sampling)
      - [Top-p Sampling (Nucleus Sampling)](#top-p-sampling-nucleus-sampling)
  - [Обучение, оценка и оптимизация модели](#обучение-оценка-и-оптимизация-модели)
    - [Настройка параметров дообучения](#настройка-параметров-дообучения)
      - [Аппаратные средства](#аппаратные-средства)
  - [Анализ результатов](#анализ-результатов)
    - [Анализ результатов обучения модели](#анализ-результатов-обучения-модели)
  - [Дальнеишее направление развития исследований](#дальнеишее-направление-развития-исследований)
  - [Заключение](#заключение)
  - [Источники](#источники)


## Абстракт

В рамках данной работы представлена задача разработки и обучения модели генерации текста, которая автоматизирует процесс создания ответов от представителей государственных органов на обращения граждан. Для решения этой задачи используется модель на основе архитектуры GPT-2 (Generative Pre-trained Transformer 2), которая дополнительно дообучается на специализированном наборе данных, включающем пары вопросов и ответов, собранных из реальной переписки между гражданами и представителями власти.

Ключевыми аспектами проекта являются подготовка и предобработка данных, обеспечивающие качественное обучение модели, включая кодирование типов сообщений и адаптацию модели для обработки конкретных запросов. Оценка качества генерируемых ответов осуществляется с помощью метрик BLEU, ROUGE и METEOR, которые позволяют количественно анализировать степень соответствия сгенерированных текстов эталонным ответам. Важной частью работы является также разработка и интеграция методов выбора следующего токена в процессе генерации текста, таких как argmax, top-k sampling и top-p (nucleus) sampling, каждый из которых предоставляет различные уровни разнообразия и предсказуемости текста.

Ссылка на репозиторий: https://github.com/AntonSHBK/NLP_course

## Введение

Развитие ИИ оказало заметное влияние на многие аспекты жизни человека, предоставив возможности для улучшения качества и доступности услуг, ускорения и оптимизации процессов принятия решений и внедрения автоматизированных систем в различные сферы деятельности. Одной из ключевых областей, демонстрирующих потенциал ИИ, является NLP, технология, позволяющая машинам понимать, интерпретировать и генерировать человеческий язык в его естественной форме.

Искусственный интеллект преобразует промышленность и социальные процессы, делая возможным автоматизацию задач, которые ранее требовали человеческого вмешательства. Это включает в себя такие области, как здравоохранение, где ИИ используется для диагностики заболеваний с высокой точностью, образование, где персонализированные учебные системы предлагают индивидуальные подходы к обучению, и транспорт, где автономные транспортные средства обещают сделать передвижение более безопасным и эффективным. Во всех этих случаях ИИ способствует повышению производительности, уменьшению ошибок и оптимизации ресурсов, что в конечном итоге ведет к более высокому качеству жизни и устойчивому развитию общества.

## Обзор литературы

Обработка естественного языка (NLP) в последние годы достигла значительных успехов благодаря развитию глубоких нейронных сетей и массовому накоплению текстовых данных. Современные NLP-системы способны не только анализировать тексты с точки зрения грамматики и синтаксиса, но и извлекать смысловые и эмоциональные составляющие, что делает их приложения чрезвычайно широкими [1]. Примеры включают автоматическую генерацию текстов, машинный перевод, создание чат-ботов для обслуживания клиентов и многое другое. Такие технологии, как трансформеры и предобученные модели вроде GPT [2] и BERT [3], значительно продвинули понимание и генерацию естественного языка, демонстрируя впечатляющие результаты в таких задачах, как ответы на вопросы, автоматическое резюмирование и персонализированная коммуникация.

В направлении развития систем взаимодействия органов исполнительной власти и граждан, ИИ позволяет автоматизировать рутинные процедуры, ускоряя обработку запросов граждан, повышая точность административных решений и улучшая доступ к публичной информации [4]. Это способствует не только оптимизации работы государственных структур, но и усилению прозрачности и открытости власти.

Обработка естественного языка играет ключевую роль в автоматизации взаимодействий между гражданами и государственными службами. NLP-технологии позволяют разрабатывать системы, способные анализировать обращения граждан, автоматически генерировать ответы на стандартные вопросы и даже проводить первичный анализ сложных запросов, требующих вмешательства специалистов. Примеры применения включают:
- **Чат-боты и виртуальные помощники**: Автоматизация первичной поддержки граждан, предоставление ответов на часто задаваемые вопросы, помощь в заполнении форм и подаче заявлений.
- **Анализ обратной связи**: Использование NLP для анализа писем, жалоб и предложений граждан, что помогает выявлять общие тренды и проблемные области, требующие внимания.
- **Автоматизация документооборота**: Преобразование неструктурированного текста в структурированную форму, автоматическая категоризация документов, что снижает ручной труд и повышает эффективность процессов.

Интеграция ИИ и NLP в государственные структуры несет не только возможности, но и вызовы, особенно в области этики и защиты данных. Важно обеспечивать защиту личной информации, предотвращать предвзятость в алгоритмах и разрабатывать системы таким образом, чтобы они были понятны и прозрачны для граждан [8, 9].

На текущий момент исследования в области генерации текстов для специфических задач продемонстрировали значительный прогресс благодаря развитию технологий машинного обучения, особенно глубокого обучения. Модели, основанные на архитектурах трансформеров, таких как GPT (Generative Pre-trained Transformer) [2] и BERT (Bidirectional Encoder Representations from Transformers) [3], выдвинулись на передний план в этой области. 

Исследования, направленные на генерацию текстов различной сложности и направленности, включают создание автоматических систем отчетности, генерацию новостей, автоматизацию написания кода, составление медицинских отчётов и многое другое. Такие системы требуют не только точного воспроизведения языковых структур, но и способности адаптироваться к специфическим требованиям домена.

Одной из выдающихся работ в этом направлении является статья Васвани и других  соавторов - "Attention is All You Need" [7], которая представила модель Трансформер (Transformer), лежащую в основе многих последующих исследований в области NLP. Эта архитектура позволила улучшить качество генерации текста за счёт лучшего улавливания контекста на длинных дистанциях.

![Рисунок трансформер](https://i.stack.imgur.com/eAKQu.png)

Примером применения специфических генеративных моделей является исследование в области медицины, где ИИ используется для создания клинических записей и отчётов на основе данных пациентов. В работе Гуанксионга и соавторов [10] исследователи разработали модель, которая автоматически генерирует описания рентгеновских снимков грудной клетки, демонстрируя высокую клиническую точность.

В сфере программирования набирают популярность инструменты, такие как GitHub Copilot, основанные на модели GPT-3 от OpenAI [11], которые могут автоматически генерировать код по запросу пользователя, облегчая процесс разработки программного обеспечения.

Ещё одним важным направлением исследований является улучшение этических аспектов генерации текста. Работа Хендерсона, Шина и других [8] затрагивает вопросы предвзятости и транспарентности в автоматизированных системах генерации текста, подчеркивая необходимость разработки решений, способных обеспечить справедливое и беспристрастное использование ИИ в общественных и частных секторах.

Интеграция текстовых данных с дополнительными метаданными становится всё более популярной в современных исследованиях в области обработки естественного языка (NLP). Это позволяет моделям более эффективно понимать контекст и улучшать качество генерации или классификации текста. Примером такой работы является исследование Кескара [12], в которой которой рассматривается генерация текста с учётом контролируемых атрибутов, таких как настроение и стилистика, используя модель GPT-2 для создания текста с заданными характеристиками. Также стоит отметить ещё одну работу группы авторов [13], в которой рассматривается многоуровневый подход к обучению представлений, обучая модель одновременно на нескольких семантических задачах, что позволяет лучше улавливать семантические связи между различными типами данных. 

Исследование Ву и Хе [14]. показывает, как включение информации о категории сущностей в архитектуру BERT улучшает понимание контекста и точность модели в задачах классификации отношений. В ещё одной работе [15]   автор рассматривает совместное обучение распознавания именованных сущностей и связывания этих сущностей с их идентификаторами в базе данных, что также демонстрирует значительное улучшение процесса распознавания и связывания.

Различные научные работы и доклады подробно исследуют, как государственные органы могут использовать NLP для улучшения коммуникаций и автоматизации процессов, что позволяет повысить качество взаимодействия с гражданами и обработку больших объемов данных.

В работе Джао и других авторов [16] рассматриваются вопросы применения ИИ в управлении и интеграции в государственные органы, а также использование NLP для автоматизации ответов на запросы граждан и улучшения доступности информации.

В другой работе группы авторов во главе Гиовани [17] рассматривается важность цифровой трансформации в государственном управлении. Авторы делают акцент на использовании NLP для оптимизации обработки запросов и предоставления более качественных услуг.

Исследование Покхреда и других авторов [18] освещает потенциал ИИ и NLP в улучшении интерактивности между гражданами и государством. Основное внимание здесь уделено упрощению доступа к информации и госуслугам через улучшенные технологии обработки языка.

В России исследования в области обработки естественного языка (NLP) активно развиваются благодаря усилиям как академических, так и коммерческих организаций. Научные исследователи и разработчики применяют современные методы машинного обучения и глубокого обучения для решения широкого спектра задач, связанных с автоматизацией обработки текстов на русском языке [23]. 

Одним из заметных достижений является разработка русскоязычной версии бенчмарка SuperGLUE группой авторов [19]. Этот документ описывает адаптацию знаменитого англоязычного теста для оценки моделей NLP, что способствует улучшению качества и эффективности русскоязычных NLP-систем.

В Высшей Школе Экономики осуществляются проекты по анализу эмоциональной окраски текстов, что важно для мониторинга социальных медиа и анализа потребительских отзывов. Московский государственный университет фокусируется на создании и анализе больших текстовых корпусов, что помогает улучшить технологии обработки русского языка и его применение в различных областях. НИУ ВШЭ разрабатывает системы для автоматического извлечения и анализа информации из новостных потоков, способствующие выявлению общественных трендов и изменений в общественном мнении. Сбербанк активно внедряет чат-боты на основе NLP для улучшения взаимодействия с клиентами, что способствует повышению качества обслуживания и оптимизации процессов.

Эти и многие другие исследования показывают динамичное развитие области генерации текстов и важность интеграции технических, этических и практических аспектов для создания надежных и функциональных систем на базе искусственного интеллекта.

## Определение области и цели проекта

В рамках данной работы представлена задача разработки и обучения модели генерации текста, которая автоматизирует процесс создания ответов от представителей государственных органов на обращения граждан. Центральной целью проекта является разработка системы, способной анализировать текстовые сообщения, поступающие от пользователей, и генерировать адекватные, информативные ответы, соответствующие заданным критериям качества и релевантности.

Для достижения этой цели необходимо выполнить следующие задачи:
1. **Определить архитектуру и конткретную базовую модель трансформера**, выбрав наиболее подходящую из доступных предобученных моделей, в зависимости от их способности к адаптации под специфические требования задачи.
2. **Модифицировать архитектуру для учета заданных параметров**, включая интеграцию дополнительных данных, таких как категория обращения или предыдущие взаимодействия пользователя с государственными службами, для повышения точности и персонализации ответов.
3. **Формирование и описание набора данных**, который будет использоваться для обучения модели. Необходимо собрать, очистить и структурировать данные, состоящие из вопросов и ответов между гражданами и государственными учреждениями, учитывая различные аспекты, такие как тип сообщения, региональные особенности и предмет обращения. Данные должны быть размечены для обучения с учетом контекста и специфики задачи.
4. **Установить и определить метрики для оценки адекватности генерирования текста**, а также разработать методику их применения для оценки как точности, так и естественности текстов.
5. **Установить способы генерации текста**, определив и интегрировав различные стратегии для генерации более качественных и разнообразных текстовых ответов.
6. **Обучить модель**, проведя тренировку на собранных и обработанных данных с целью достижения оптимальной производительности и точности ответов.
7. **Сравнить полученные результаты** с эталонными ответами (предыдущими моделями) для оценки прогресса и эффективности новой системы, используя установленные метрики.

## Сбор и подготовка данных

Данный датасет собран из открытых источников, в частности, с официального аккаунта Администрации Губернатора и Правительства Московской области на платформе ВКонтакте [20]. Основу датасета составляют тексты сообщений пользователей, размещённые на постах и в комментариях к публикациям администрации, а также ответы от представителей государственных органов или соответствующих компетентных структур. Сбор данных осуществлялся с использованием специально разработанного краулера, который автоматизировал процесс экстракции текстовых данных.

Исходная информация (полученная краулером) имеет только: автора сообщения гражданина, текст сообщения, автора заинтересованной структуры, текст ответа. Другие параметры данных получают путём предварительной обработки данных, куда входит: определение тематики сообщения, тип сообщения, определение ответственной организации, категорию сообщения, определение региона. 

Все эти параметры помечаются (разметка данных) в автоматизированном  режиме, за исключением ответственного. Данные о принадлежности ответственных персон к определённым структурным подразделениям стало возможным благодаря предоставленной информации коллеги из администрации Московской области. Адрес назначается по контекстным данным, указанным в сообщении. Категория,  тип и тематика сообщения размечаются обученными языковыми моделями (BERT-подобными), точность моделей варьируется от 70 - 85%.

Датасет содержит информацию о взаимодействиях граждан с представителями госорганов, 8  параметров. Детальное описание структуры данных:

1. **responsible_person** - Персона или организация, ответственная за решение проблемы (например, "Администрация Химки").

2. **type_problem** - Тип проблемы, которую необходимо решить (например, "Устранение проблемы").

3. **topic** - Тема обращения, описывает конкретную проблему или вопрос (например, "Неудовлетворительное качество товара, оказания услуг").

4. **categoria** - Категория вопроса или проблемы (например, "Торговля, товары и услуги").

5. **region** - Регион, откуда поступило обращение (например, "Орехово-Зуевский").

6. **source** - Источник обращения или контекст, в котором возник вопрос. Содержит описание ситуации, которая привела к обращению (например, текст о цифровизации услуг).

7. **target** - Ответ уполномоченного лица госорганов на обращение гражданина. Содержит текстовый ответ на поставленный вопрос или проблему.

8. **context** - Дополнительный контекст обращения,содержит всю переписку участников диалога.

Датасет содержит только текстовую информацию (текст сообщений, метки, категории), включает 11475 записей, из которых 11140 содержат полную информацию без пропусков. Данные записаны в формате csv, размер файла 6452 КБ. К данным не применялась предварительная обработка данных (очистка). Данные разделены на тренировочный и валидационный наборы, последний составляет 10% от общего объёма данных, при этом данные были случайно перемешаны. В сообщениях присутствует дополнительная информация, такая как ссылки, смайлики и упоминания пользователей (id пользователей которых цитировали или упоминали), которая может создавать шум. Помимо  этого в данных присутствует дублирование сообщений пользователей, это связано с тем, что на одно сообщение необходим ответ нескольких ответственных лиц, имеющих различную юрисдикцию в решении проблема автора.  Эти факторы следует учитывать при обработке и анализе данных. Представленные данные использованы в обучении и валидации модели.

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>responsible_person</th>
      <th>type_problem</th>
      <th>topic</th>
      <th>categoria</th>
      <th>region</th>
      <th>source</th>
      <th>target</th>
      <th>context</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>11475</td>
      <td>11475</td>
      <td>11475</td>
      <td>11475</td>
      <td>11475</td>
      <td>11150</td>
      <td>11465</td>
      <td>11475</td>
    </tr>
    <tr>
      <th>unique</th>
      <td>181</td>
      <td>11</td>
      <td>120</td>
      <td>11</td>
      <td>56</td>
      <td>5534</td>
      <td>9821</td>
      <td>5694</td>
    </tr>
    <tr>
      <th>top</th>
      <td>Александр Αлексеев</td>
      <td>Устранение проблемы</td>
      <td>-</td>
      <td>ЖКХ</td>
      <td>Другие регионы</td>
      <td>Это ситуация в доме 15/2 - результат полного о...</td>
      <td>Здравствуйте! Спасибо за Ваш вопрос. В микрора...</td>
      <td>[id4847589|Александр], кто ответит за нанесён...</td>
    </tr>
    <tr>
      <th>freq</th>
      <td>717</td>
      <td>8365</td>
      <td>1663</td>
      <td>4848</td>
      <td>2513</td>
      <td>24</td>
      <td>111</td>
      <td>24</td>
    </tr>
  </tbody>
</table>
</div>

![Рисунки распределения данных](/docs/imgs/categoria_hist.png?raw=true)

![Рисунки распределения данных](/docs/imgs/type_problem_hist.png?raw=true)

## Выбор технологии и архитектуры модели

### Описание модели и её модификации

В качестве базовой модели было принято решение использовать архитектуру GPT-2 [21], предварительно облученную модель ai-forever/rugpt3small_based_on_gpt2 [6], предназначенная для работы с русским языком. Этот выбор обусловлен высокой адаптируемостью модели к задачам генерации текста и её способностью обрабатывать большие объёмы информации для создания качественных текстовых ответов. Предварительное обучение на обширном текстовом корпусе обеспечивает модели прочную базу для дальнейшей настройки и дообучения под специфические задачи.

Разрабатываемая модель представляет собой модифицированную версию стандартной архитектуры GPT-2, адаптированную для специфических нужд взаимодействия с пользователями в контексте диалога с представителями власти. Основные модификации касаются интеграции дополнительных данных о типе сообщения, что позволяет модели более точно адаптироваться к контексту запросов и предоставлять релевантные ответы.

В качестве фреймворка проектирования модели используется PyTorch [22].

Модель включает слой nn.Embedding, что позволяет встраивать информацию о типе сообщения непосредственно в процесс обработки данных, это усиливает контекстуальное понимание модели. Дополнительный линейный слой nn.Linear интегрирует эмбеддинги типа сообщения с токенными эмбеддингами, обеспечивая корректный проход базовой модели. Выходной линейный слой преобразует последние скрытые состояния в логиты, необходимые для генерации последующих токенов.

![Рисунок модели](/docs/imgs/CustomGPT2ModelArchitecture.png?raw=true)

В функции передачи данных `forward`, проектируемой модели, процесс начинается с генерации эмбеддингов для каждого токена и типа сообщения. Эти эмбеддинги затем комбинируются и усиливаются дополнительным линейным слоем (размер слоя равен размеру скрытого слоя базовой модели. 768), известным как. После этого, комбинированные эмбеддинги подаются в основную часть модели GPT-2. Модель обрабатывает входные данные, учитывая маску внимания, что позволяет модели сосредоточиться на релевантных частях входной последовательности. В завершающем этапе, последние скрытые состояния, полученные от GPT-2, преобразуются в логиты с помощью выходного линейного слоя (размер слоя равен размеру словаря). Эти логиты представляют собой вероятности следующих токенов, которые модель использует для генерации текста, обеспечивая по идее тем самым точность и релевантность генерируемых ответов.

В качестве оптимизатора модели для обучения был выбран оптимизатор AdamW [24], который является модификацией традиционного алгоритма Adam [25]. AdamW вносит улучшения в обработку штрафов за регуляризацию, что помогает лучше контролировать веса в сети и предотвращает их чрезмерный рост, обеспечивая более стабильное и эффективное обучение.

В качестве функции потерь была выбрана CrossEntropyLoss [26], которая широко используется для задач классификации с множественными классами. Эта функция потерь оценивает, насколько вероятности, предсказанные моделью для каждого класса, соответствуют фактическим меткам класса.

### Метрики валидации

Для оценки качества генерируемых текстов рассмотрим использование трёх широко распространённых метрики: BLEU [27], ROUGE [28] и METEOR [29]. Эти метрики позволяют количественно анализировать соответствие сгенерированных ответов эталонным ответам и оценивать их по различным аспектам качества, таким как точность, покрытие и упорядоченность.

#### BLEU (Bilingual Evaluation Understudy)
BLEU — это одна из наиболее популярных метрик для оценки качества машинного перевода, которая также широко применяется для задач генерации текста. BLEU измеряет, насколько n-граммы сгенерированного текста совпадают с n-граммами в эталонных текстах, учитывая их частоту вплоть до заданного размера n. BLEU оценивает точность, но с поправкой на «штраф за длину», чтобы избежать чрезмерно кратких ответов, которые искусственно могли бы увеличить совпадение n-грамм [27].

BLEU оценка рассчитывается следующим образом:

1. **Совпадение n-грамм**: Для каждой n-граммы в сгенерированном тексте проверяется, встречается ли она в эталонном тексте. Для каждой n-граммы вычисляется отношение числа совпадений к общему числу n-грамм в сгенерированном тексте.
   
   $$Precision_n = \frac{\sum_{\text{n-gram} \in \text{Candidate}} \min(\text{Count}(\text{n-gram}), \text{MaxRefCount}(\text{n-gram}))}{\sum_{\text{n-gram}\in \text{Candidate}} \text{Count}(\text{n-gram})}$$

   где `MaxRefCount(n-gram)` — максимальное количество данной n-граммы среди всех эталонных текстов, `Count(n-gram)` — количество данной n-граммы в кандидате.

2. **Геометрическое среднее**: Вычисляется геометрическое среднее из точностей n-грамм для различных n.

3. **Штраф за короткие тексты (Brevity Penalty, BP)**: Если сгенерированный текст короче эталонного, вводится штраф за короткую длину для предотвращения предпочтения необоснованно коротких ответов.

$$BP = 
\begin{cases} 
1 & \text{если } c > r \\ 
e^{(1-r/c)} & \text{если } c \leq r 
\end{cases}$$

   где `c` — длина сгенерированного текста, а `r` — длина эталонного текста или средняя длина нескольких эталонных текстов.

Итоговая оценка BLEU вычисляется как произведение геометрического среднего точности по всем n-граммам на штраф за короткие тексты (BP).

#### ROUGE (Recall-Oriented Understudy for Gisting Evaluation)
ROUGE используется для оценки автоматических рефератов или переводов и сосредоточена на полноте ответа, т.е., сколько n-грамм эталонного ответа захватывает сгенерированный ответ. ROUGE-L и ROUGE-N (где N указывает на размер n-грамм) — наиболее распространённые вариации [28].

Формула ROUGE-N:
$$ \text{ROUGE-N} = \frac{\sum_{s \in \text{Reference Summaries}} \sum_{n \in s} \text{Count}_{\text{match}}(n)}{\sum_{s \in \text{Reference Summaries}} \sum_{n \in s} \text{Count}(n)} $$

**ROUGE-L** фокусируется на длине наиболее длинной общей подпоследовательности, что позволяет оценить не только наличие ключевых слов и фраз, но и их последовательность в тексте, что важно для оценки качества и естественности текста.

#### METEOR (Metric for Evaluation of Translation with Explicit ORdering)
ETEOR — это метрика для оценки машинного перевода, которая была разработана как альтернатива BLEU для лучшего учета качества перевода с точки зрения человеческой оценки. Она учитывает не только точное совпадение слов, но и синонимы, стемминг и порядок слов, позволяя получить более гибкую и всестороннюю оценку. В отличие от BLEU, METEOR учитывает как точность, так и полноту, вводя понятия precision (P) и recall (R), и использует их для вычисления F-меры. Кроме того, METEOR вводит понятие "штраф за непоследовательность" (penalty), учитывающее различия в порядке слов между сгенерированным текстом и эталонным [29].

Основная формула METEOR включает в себя вычисление F-меры и штрафа за непоследовательность:

$$ \text{METEOR} = (1 - \text{penalty}) \cdot F_{\text{mean}} $$

где

$$ F_{\text{mean}} = \frac{10 \cdot P \cdot R}{R + 9 \cdot P} $$

- $P$ — точность (precision), доля совпадающих слов в переводе относительно общего числа слов в сгенерированном тексте.
- $R$ — полнота (recall), доля совпадающих слов в переводе относительно общего числа слов в эталонном тексте.
- $\text{penalty}$ — штраф за непоследовательность, вычисляемый на основе числа и длины совпадающих фрагментов слов в сгенерированном и эталонном текстах.

Существуют и другие метрики оценки, однако остановимся на наиболее распространённых методах.

### Генерация текста

В данной работе рассмотрены четыре основных метода генерации текста, которые широко используются в современных моделях генерации естественного языка. Каждый из этих методов имеет свои особенности и применяется для достижения различных аспектов разнообразия и точности в сгенерированных текстах [30].

#### Argmax
Этот метод выбирает следующий токен в последовательности, основываясь на максимальной вероятности из распределения логитов, предсказанных моделью. Это самый простой и детерминированный способ генерации текста.

Формула argmax:
$$ \text{next\_token} = \arg\max(logits) $$

#### Temperature Sampling
Temperature sampling модифицирует распределение вероятностей, делая его более "мягким" или "жестким", в зависимости от значения параметра температуры $T$. При $T > 1$ распределение становится более равномерным, что увеличивает разнообразие генерируемых ответов. При $T < 1$ распределение становится более "острым", уменьшая разнообразие и увеличивая детерминированность выбора.

Формула temperature sampling:
$$ P(i) = \frac{\exp(\log(p_i)/T)}{\sum_j \exp(\log(p_j)/T)} $$
где $ p_i $ — исходная вероятность токена $ i $.

#### Top-k Sampling
Top-k sampling ограничивает выборку следующего токена только $k$ наиболее вероятными токенами. Этот метод уменьшает риск выбора маловероятных токенов и позволяет сосредоточиться на более вероятных вариантах, что улучшает когерентность текста при сохранении элемента случайности.

Формула Top-k Sampling:
Выбирается подмножество токенов $C$ из всех возможных токенов $V$, где $|C| = k$ и каждый токен из $CS$ имеет максимальные вероятности из $V$. Затем выполняется:
$$ P(i) = \begin{cases} 
\frac{p_i}{\sum_{j \in C} p_j} & \text{if } i \in C \\
0 & \text{otherwise}
\end{cases} $$

#### Top-p Sampling (Nucleus Sampling)
Top-p sampling, также известный как nucleus sampling, выбирает минимальный набор токенов $C$, сумма вероятностей которых составляет $p$. Это позволяет исключить наименее вероятные токены и сосредоточить выборку на более вероятном "ядре" распределения.

Формула Top-p Sampling:
Выбираются токены так, что:
$$ \sum_{i \in C} p_i \geq p $$
и выполняется нормализация вероятностей для токенов в $C$:
$$ P(i) = \begin{cases} 
\frac{p_i}{\sum_{j \in C} p_j} & \text{if } i \in C \\
0 & \text{otherwise}
\end{cases} $$

## Обучение, оценка и оптимизация модели

### Настройка параметров дообучения

Дообучение модели настраивается с учётом следующих гиперпараметров:
- **Максимальная длина последовательности**: `max_length=64` обеспечивает баланс между детализацией ответов и вычислительной эффективностью;
- **Размер батча**: `batch_size=64` обеспечивает  балансированную загрузку данных в модель во время обучения;
- **Размер тестового набора**: `test_size=0.1` позволяет выделить 10% данных для валидации модели;
- **Скорость обучения**: `learning_rate=1e-5`;
- **Количество эпох**: `num_epochs=30`;
- **Коэффициент температуры**:`temperature`=0.7;
- **Коэффициент top_k** `top_k`=11;
- **Коэффициент top_p** `top_p`=0.9.

#### Аппаратные средства

Для обучения модели использовались следующие аппаратные средства:
- **Процессор**: 12th Gen Intel(R) Core(TM) i5-1240P с тактовой частотой 1.70 GHz, что обеспечивает достаточную мощность для обработки данных и расчётов.
- **Оперативная память**: 64,0 ГБ, что позволяет эффективно работать с большими объёмами данных и управлять несколькими процессами одновременно без существенной потери производительности.
- **Видеокарта**: NVIDIA RTX A6000, одна из передовых графических карт, которая поддерживает ускорение вычислений с помощью CUDA. 

Обучение модели производилось с использованием библиотеки `PyTorch` и технологии `CUDA`, что позволило полностью использовать вычислительные мощности графического процессора для обработки операций при обучении. Это значительно сократило время обучения и повысило его эффективность.Время обучения модели составило 28 минут и 43 секунды. Это относительно короткий период для моделей такого типа, благодаря чему проект может быть быстро адаптирован и масштабирован.После завершения обучения веса модели были сохранены для последующего использования. Это позволяет легко воспроизвести результаты и использовать обученную модель для генерации ответов без необходимости повторного обучения.

## Анализ результатов

### Анализ результатов обучения модели

По итогам обучения модели `CustomGPT2Model`, основанной на архитектуре GPT-2, можно сделать несколько ключевых наблюдений. График обучения показывает, что потери как на этапе обучения, так и валидации постепенно уменьшаются, что свидетельствует о стабилизации процесса обучения и адаптации модели к задаче. Однако, несмотря на уменьшение потерь, анализ сгенерированных текстов выявляет значительные проблемы с качеством и релевантностью ответов.

Выводы, полученные в результате анализа, указывают на то, что несмотря на некоторые успехи в обучении (например, способность модели улавливать ключевые слова из запросов), генерация текста не соответствует заданным стандартам качества и релевантности. Это означает, что текущая реализация модели требует дополнительной доработки, включая возможное изменение подходов к обучению и более глубокое изучение данных, на которых обучается модель.

Разработанный алгоритм продемонстрировал свою работоспособность и потенциал для дальнейших улучшений. Несмотря на текущие трудности с релевантностью и качеством сгенерированных текстов, алгоритм успешно справился с базовой задачей генерации текста, что является важным шагом на пути к созданию полноценной системы автоматизированного ответа на обращения граждан.

Возможности для дальнейшего развития алгоритма включают его видоизменение и адаптацию под конкретные потребности и условия использования. Основываясь на анализе выбранных метрик качества, таких как BLEU, ROUGE и METEOR, и используя различные методы генерации текста (temperature sampling, Top-k sampling, Top-p sampling), можно добиться значительного улучшения качества и релевантности ответов модели.

Эти метрики и методы предоставляют ценные инструменты для оценки и настройки модели, позволяя точно определить области, требующие улучшения, и систематически подходить к их оптимизации. Постепенное уточнение параметров обучения и адаптация модели к специфике задачи могут значительно повысить её эффективность и удовлетворительность ответов.

## Дальнеишее направление развития исследований

В рамках дальнейшего развития проекта по генерации текстовых ответов от представителей государственных органов планируется провести ряд ключевых исследований и улучшений. Основное внимание будет уделено пересмотру и возможной модификации архитектуры модели. Это включает в себя сравнение текущей модели GPT-2 с другими подходами и архитектурами, которые могут лучше справляться с задачей учета контекста запросов и генерации более релевантных ответов.

Одним из важных направлений будет расширение и дополнительная балансировка набора входных данных. Планируется обогатить датасет более разнообразными примерами обращений, чтобы улучшить способность модели адаптироваться к различным типам запросов и минимизировать предвзятость в ответах. Это потребует тщательного анализа текущих данных и возможно, включение новых источников информации.

Также будет проведен анализ различных методов генерации текста, таких как argmax, temperature sampling, Top-k и Top-p sampling, для определения наиболее эффективных способов в контексте задачи. Это исследование поможет найти оптимальный баланс между разнообразием и точностью ответов, что является критически важным для повышения качества обслуживания пользователей.

Наконец, предстоит масштабирование модели для её интеграции в реальную рабочую среду. Это включает в себя разработку и тестирование API для взаимодействия с моделью, а также подготовку инфраструктуры для её эффективного и безопасного использования в продуктивной среде. Интеграция модели в рабочий сервис позволит оценить её эффективность в реальных условиях и определить дополнительные области для улучшения.

Эти шаги помогут не только улучшить качество модели, но и обеспечить её устойчивость и адаптивность к меняющимся условиям использования, что крайне важно для долгосрочного применения в государственных органах и службах.

## Заключение

В ходе реализации проекта была разработана и обучена модель, основанная на архитектуре GPT-2, для автоматизации процесса генерации ответов на обращения граждан от представителей государственных органов. Обучение модели было успешно проведено на современной аппаратной платформе, и модель демонстрирует способность генерировать текстовые ответы. Однако, результаты анализа качества сгенерированных текстов показали, что релевантность и понятность этих ответов оставляют желать лучшего. Тексты часто получаются непонятными и не полностью соответствуют заданному контексту запросов, что свидетельствует о недостаточной адаптации модели к специфике задачи.

Эти наблюдения указывают на необходимость дальнейшей работы и более глубокого анализа модели. Возможно, потребуется пересмотреть подходы к дообучению, внести корректировки в архитектуру или параметры обучения, а также использовать более обширные или детализированные обучающие данные. Также целесообразно применить дополнительные методы оценки качества и релевантности ответов для более точной настройки модели под реальные потребности пользователей.

Таким образом, хотя первоначальные результаты показывают определённый потенциал применения модели GPT-2 для автоматизации ответов государственных органов, проект требует дополнительных исследований и улучшений.

## Источники

1. Pais, Sebastião; Cordeiro, João; Jamil, M. Luqman. "NLP-based platform as a service: a brief review." *Journal of Big Data*, vol. 9, 2022. DOI: 10.1186/s40537-022-00603-5.

2. Radford, Alec; Narasimhan, Karthik; Salimans, Tim; Sutskever, Ilya. "Improving Language Understanding by Generative Pre-training." *OpenAI Blog*, 2018. Available at: [https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf).

3. Devlin, Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina. "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding." 2019. arXiv:1810.04805 [cs.CL].

4. Ferreira, Carlos. "A short review of the main concerns in A.I. development and application within the public sector supported by NLP and TM." 2023.

5. OpenAI and others. "GPT-4 Technical Report." 2024. arXiv:2303.08774 [cs.CL].

6. Zmitrovich, Dmitry and others. "A Family of Pretrained Transformer Language Models for Russian." 2023. arXiv:2309.10931 [cs.CL].

7. Vaswani, Ashish and others. "Attention Is All You Need." 2023. arXiv:1706.03762 [cs.CL].

8. Henderson, Peter and others. "Ethical Challenges in Data-Driven Dialogue Systems." 2017. arXiv:1711.09050 [cs.CL].

9. Corbett-Davies, Sam and others. "The Measure and Mismeasure of Fairness." 2023. arXiv:1808.00023 [cs.CY].

10. Liu, Guanxiong and others. "Clinically Accurate Chest X-Ray Report Generation." 2019. arXiv:1904.02633 [cs.CV].

11. GitHub. "Introducing GitHub Copilot: your AI pair programmer." 2021. Accessed: 2023-04-12. Available at: [https://github.blog/2021-06-29-introducing-github-copilot-ai-pair-programmer/](https://github.blog/2021-06-29-introducing-github-copilot-ai-pair-programmer/).

12. Keskar, Nitish Shirish and others. "CTRL: A Conditional Transformer Language Model for Controllable Generation." 2019. arXiv:1909.05858 [cs.CL].

13. Sanh, Victor; Wolf, Thomas; Ruder, Sebastian. "A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks." 2018. arXiv:1811.06031 [cs.CL].

14. Wu, Shanchan; He, Yifan. "Enriching Pre-trained Language Model with Entity Information for Relation Classification." 2019. arXiv:1905.08284 [cs.CL].

15. Martins, Pedro Henrique; Marinho, Zita; Martins, André F. T. "Joint Learning of Named Entity Recognition and Entity Linking." 2019. arXiv:1907.08243 [cs.CL].

16. Reis, João; Espírito Santo, Paula; Melao, Nuno. "Artificial Intelligence in Government Services: A Systematic Literature Review." 2019. ISBN 978-3-030-16180-4. DOI: 10.1007/978-3-030-16181-1_23.

17. Liva, Giovanni and others. "Exploring digital government transformation: a literature review." *Proceedings*, September 2020. DOI: 10.1145/3428502.3428578.

18. Pokhrel, Shiva Raj and others. "Policy-based Bigdata Security and QoS Framework for SDN/IoT: An Analytic Approach." *IEEE INFOCOM 2019 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)*, 2019, pp. 73-78. DOI: 10.1109/INFCOMW.2019.8845234.

19. Fenogenova, Alena and others. "Russian SuperGLUE 1.1: Revising the Lessons not Learned by Russian NLP models." 2022. arXiv:2202.07791 [cs.CL].

20. Administration of the Governor and Government of Moscow Region. "Official VKontakte Account of the Administration of the Governor and Government of Moscow Region." 2023. Accessed: 2023-04-12. Available at: [https://vk.com/pressmo](https://vk.com/pressmo).

21. Radford, Alec and others. "Language Models are Unsupervised Multitask Learners." *OpenAI Blog*, 2019. Available at: [https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf).

22. Paszke, Adam and others. "PyTorch: An Imperative Style, High-Performance Deep Learning Library." *Advances in Neural Information Processing Systems*, vol. 32, 2019. Publisher: Curran Associates, Inc. Available at: [https://pytorch.org](https://pytorch.org).

23. Mitkov, Ruslan and others, eds. "Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)." Held online, September 2021. Publisher: INCOMA Ltd. Available at: [https://aclanthology.org/2021.ranlp-1.0](https://aclanthology.org/2021.ranlp-1.0).

24. Loshchilov, Ilya; Hutter, Frank. "Decoupled Weight Decay Regularization." *arXiv preprint arXiv:1711.05101*, 2018. Available at: [https://arxiv.org/abs/1711.05101](https://arxiv.org/abs/1711.05101).

25. Kingma, Diederik P.; Ba, Jimmy. "Adam: A Method for Stochastic Optimization." *arXiv preprint arXiv:1412.6980*, 2014. Available at: [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980).

26. Goodfellow, Ian; Bengio, Yoshua; Courville, Aaron. "Deep Learning." MIT Press, 2016. Available at: [http://www.deeplearningbook.org](http://www.deeplearningbook.org).

27. Papineni, Kishore and others. "BLEU: a method for automatic evaluation of machine translation." *Proceedings of the 40th annual meeting of the Association for Computational Linguistics*, 2002, pp. 311–318.

28. Lin, Chin-Yew. "ROUGE: A Package for Automatic Evaluation of Summaries." *Text summarization branches out*, 2004, pp. 74–81.

29. Banerjee, Satanjeev; Lavie, Alon. "METEOR: An automatic metric for MT evaluation with improved correlation with human judgments." *Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization*, 2005, pp. 65–72.

30. Holtzman, Ari and others. "The Curious Case of Neural Text Degeneration." *arXiv preprint arXiv:1904.09751*, 2019.