{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gensim.downloader as api\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# путь к data\n",
    "DATA_PATH = \"../../data/task_2/\"\n",
    "# Глобальное значение \"random_state\" \n",
    "STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns in the train data set: (48665, 3)\n",
      "Number of rows and columns in the valid data set: (12167, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>text</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Очень понравилось. Были в начале марта  с соба...</td>\n",
       "      <td>очень понравиться начало март собака дойти лес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом магазин устраивает.\\nАссортимент позво...</td>\n",
       "      <td>целое магазин устраивать ассортимент позволять...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Очень хорошо что открылась 5 ка, теперь не над...</td>\n",
       "      <td>очень открыться ка далеко ехать рядом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Пятёрочка громко объявила о том как она заботи...</td>\n",
       "      <td>пята рочко громко объявить заботиться пенсионе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Тесно, вечная сутолока, между рядами трудно ра...</td>\n",
       "      <td>тесно вечный сутолока ряд трудно разойтись гря...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate                                               text  \\\n",
       "0     3  Очень понравилось. Были в начале марта  с соба...   \n",
       "1     4  В целом магазин устраивает.\\nАссортимент позво...   \n",
       "2     4  Очень хорошо что открылась 5 ка, теперь не над...   \n",
       "3     2  Пятёрочка громко объявила о том как она заботи...   \n",
       "4     2  Тесно, вечная сутолока, между рядами трудно ра...   \n",
       "\n",
       "                                          clear_text  \n",
       "0  очень понравиться начало март собака дойти лес...  \n",
       "1  целое магазин устраивать ассортимент позволять...  \n",
       "2              очень открыться ка далеко ехать рядом  \n",
       "3  пята рочко громко объявить заботиться пенсионе...  \n",
       "4  тесно вечный сутолока ряд трудно разойтись гря...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(DATA_PATH, \"test.csv\"))\n",
    "print(\"Number of rows and columns in the train data set:\", train_data.shape)\n",
    "print(\"Number of rows and columns in the valid data set:\", test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48665 entries, 0 to 48664\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   rate        48665 non-null  int64 \n",
      " 1   text        48665 non-null  object\n",
      " 2   clear_text  48543 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['rate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['rate'].hist(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>text</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Очень понравилось. Были в начале марта  с соба...</td>\n",
       "      <td>очень понравиться начало март собака дойти лес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом магазин устраивает.\\nАссортимент позво...</td>\n",
       "      <td>целое магазин устраивать ассортимент позволять...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Очень хорошо что открылась 5 ка, теперь не над...</td>\n",
       "      <td>очень открыться ка далеко ехать рядом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Пятёрочка громко объявила о том как она заботи...</td>\n",
       "      <td>пята рочко громко объявить заботиться пенсионе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Тесно, вечная сутолока, между рядами трудно ра...</td>\n",
       "      <td>тесно вечный сутолока ряд трудно разойтись гря...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate                                               text  \\\n",
       "0     3  Очень понравилось. Были в начале марта  с соба...   \n",
       "1     4  В целом магазин устраивает.\\nАссортимент позво...   \n",
       "2     4  Очень хорошо что открылась 5 ка, теперь не над...   \n",
       "3     2  Пятёрочка громко объявила о том как она заботи...   \n",
       "4     2  Тесно, вечная сутолока, между рядами трудно ра...   \n",
       "\n",
       "                                          clear_text  \n",
       "0  очень понравиться начало март собака дойти лес...  \n",
       "1  целое магазин устраивать ассортимент позволять...  \n",
       "2              очень открыться ка далеко ехать рядом  \n",
       "3  пята рочко громко объявить заботиться пенсионе...  \n",
       "4  тесно вечный сутолока ряд трудно разойтись гря...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "train_data['rate'] = le.fit_transform(train_data['rate'])\n",
    "\n",
    "# Оптимизация типов данных\n",
    "train_data['rate'] = train_data['rate'].astype('uint8')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48665 entries, 0 to 48664\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   rate        48665 non-null  uint8 \n",
      " 1   text        48665 non-null  object\n",
      " 2   clear_text  48543 non-null  object\n",
      "dtypes: object(2), uint8(1)\n",
      "memory usage: 808.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import pymorphy2\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Загрузка русских стоп-слов\n",
    "nltk.download('stopwords')\n",
    "russian_stopwords = stopwords.words('russian')\n",
    "\n",
    "# Инициализация анализатора pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "# Инициализируем стеммер\n",
    "stemmer = SnowballStemmer('russian')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Удаление лишних символов и нормализация\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Удаление знаков пунктуации\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n",
    "    \n",
    "    # Дополнительно: удаление специальных символов или любых символов, кроме букв (латиница или кириллица)\n",
    "    text = re.sub(r\"[^a-zA-Zа-яА-Я\\s]\", \" \", text)\n",
    "\n",
    "    # Удаление множество пробелов\n",
    "    text = text.replace(r'\\s+','')\n",
    "    \n",
    "    \n",
    "    # Токенизация\n",
    "    tokens = word_tokenize(text, language=\"russian\")\n",
    "    \n",
    "    # Удаление стоп-слов и лемматизация\n",
    "    words_lemmatized = [morph.parse(word)[0].normal_form for word in tokens if word not in russian_stopwords]\n",
    "    \n",
    "    # Удаление стоп-слов и стемминг\n",
    "    # words_stemmed = [stemmer.stem(word) for word in words if word not in russian_stopwords]\n",
    "    \n",
    "    return ' '.join(words_lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Предварительная обработка текста\n",
    "train_data['clear_text'] = train_data['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['clear_text'] = train_data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self, word_pattern=\"[\\w']+\"):\n",
    "        \"\"\"\n",
    "        Simple tokenizer that splits the sentence by given regex pattern\n",
    "        :param word_pattern: pattern that determines word boundaries\n",
    "        \"\"\"\n",
    "        self.word_pattern = re.compile(word_pattern)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return self.word_pattern.findall(text)\n",
    "\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, tokenized_texts: List[List[str]], max_vocab_size=None):\n",
    "        \"\"\"\n",
    "        Builds a vocabulary by concatenating all tokenized texts and counting words.\n",
    "        Most common words are placed in vocabulary, others are replaced with [UNK] token\n",
    "        :param tokenized_texts: texts to build a vocab\n",
    "        :param max_vocab_size: amount of words in vocabulary\n",
    "        \"\"\"\n",
    "        counts = Counter(chain(*tokenized_texts))\n",
    "        max_vocab_size = max_vocab_size or len(counts)\n",
    "        common_pairs = counts.most_common(max_vocab_size)\n",
    "        self.PAD_IDX = 0\n",
    "        self.UNK_IDX = 1\n",
    "        self.EOS_IDX = 2\n",
    "        self.itos = [\"<PAD>\", \"<UNK>\", \"<EOS>\"] + [pair[0]\n",
    "                                                   for pair in common_pairs]\n",
    "        self.stoi = {token: i for i, token in enumerate(self.itos)}\n",
    "\n",
    "    def vectorize(self, text: List[str]):\n",
    "        \"\"\"\n",
    "        Maps each token to it's index in the vocabulary\n",
    "        :param text: sequence of tokens\n",
    "        :return: vectorized sequence\n",
    "        \"\"\"\n",
    "        return [self.stoi.get(tok, self.UNK_IDX) for tok in text]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.itos)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenized_texts, labels, vocab: Vocab):\n",
    "        \"\"\"\n",
    "        A Dataset for the task\n",
    "        :param tokenized_texts: texts from a train/val/test split\n",
    "        :param labels: corresponding toxicity ratings\n",
    "        :param vocab: vocabulary with indexed tokens\n",
    "        \"\"\"\n",
    "        self.texts = tokenized_texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return (\n",
    "            self.vocab.vectorize(self.texts[item]) + [self.vocab.EOS_IDX],\n",
    "            self.labels[item],\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"\n",
    "        Technical method to form a batch to feed into recurrent network\n",
    "        \"\"\"\n",
    "        tmp = pack_sequence(\n",
    "            [torch.tensor(pair[0]) for pair in batch], enforce_sorted=False\n",
    "        ), torch.tensor([pair[1] for pair in batch])\n",
    "        return tmp\n",
    "\n",
    "\n",
    "def train_test_split(data, train_frac=0.85):\n",
    "    \"\"\"\n",
    "    Splits the data into train and test parts, stratifying by labels.\n",
    "    Should it shuffle the data before split?\n",
    "    :param data: dataset to split\n",
    "    :param train_frac: proportion of train examples\n",
    "    :return: texts and labels for each split\n",
    "    \"\"\"\n",
    "    n_toxicity_ratings = 5\n",
    "    train_labels = []\n",
    "    val_labels = []\n",
    "    train_texts = []\n",
    "    val_texts = []\n",
    "    for label in range(n_toxicity_ratings):\n",
    "        texts = data[data['rate'] == label]['clear_text'].values\n",
    "        n_train = int(len(texts) * train_frac)\n",
    "        n_val = len(texts) - n_train\n",
    "        train_texts.extend(texts[:n_train])\n",
    "        val_texts.extend(texts[n_train:])\n",
    "        train_labels += [label] * n_train\n",
    "        val_labels += [label] * n_val\n",
    "    return train_texts, train_labels, val_texts, val_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import sigmoid, relu, elu, tanh\n",
    "from torch.nn import Module, Embedding, LSTM, RNN, GRU, Linear, Sequential, Dropout\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "\n",
    "# from dataset import Vocab\n",
    "\n",
    "\n",
    "def prepare_emb_matrix(gensim_model, vocab: Vocab):\n",
    "    \"\"\"\n",
    "    Extract embedding matrix from Gensim model for words in Vocab.\n",
    "    Initialize embeddings not presented in `gensim_model` randomly\n",
    "    :param gensim_model: W2V Gensim model\n",
    "    :param vocab: vocabulary\n",
    "    :return: embedding matrix\n",
    "    \"\"\"\n",
    "    mean = gensim_model.vectors.mean(1).mean()\n",
    "    std = gensim_model.vectors.std(1).mean()\n",
    "    vec_size = gensim_model.vector_size\n",
    "    emb_matrix = torch.zeros((len(vocab), vec_size))\n",
    "    for i, word in enumerate(vocab.itos[1:], 1):\n",
    "        try:\n",
    "            emb_matrix[i] = torch.tensor(gensim_model.get_vector(word))\n",
    "        except KeyError:\n",
    "            emb_matrix[i] = torch.randn(vec_size) * std + mean\n",
    "    return emb_matrix\n",
    "\n",
    "\n",
    "class RecurrentClassifier(Module):\n",
    "    def __init__(self, config: Dict, vocab: Vocab, emb_matrix):\n",
    "        \"\"\"\n",
    "        Baseline classifier, hyperparameters are passed in `config`.\n",
    "        Consists of recurrent part and a classifier (Multilayer Perceptron) part\n",
    "        Keys are:\n",
    "            - freeze: whether word embeddings should be frozen\n",
    "            - cell_type: one of: RNN, GRU, LSTM, which recurrent cell model should use\n",
    "            - hidden_size: size of hidden state for recurrent cell\n",
    "            - num_layers: amount of recurrent cells in the model\n",
    "            - cell_dropout: dropout rate between recurrent cells (not applied if model has only one cell!)\n",
    "            - bidirectional: boolean, whether to use unidirectional of bidirectional model\n",
    "            - out_activation: one of: \"sigmoid\", \"tanh\", \"relu\", \"elu\". Activation in classifier part\n",
    "            - out_dropout: dropout rate in classifier part\n",
    "            - out_sizes: List[int], hidden size of each layer in classifier part. Empty list means that final\n",
    "                layer is attached directly to recurrent part output\n",
    "        :param config: configuration of model\n",
    "        :param vocab: vocabulary\n",
    "        :param emb_matrix: embeddings matrix from `prepare_emb_matrix`\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.vocab = vocab\n",
    "        self.emb_matrix = emb_matrix\n",
    "        self.embeddings = Embedding.from_pretrained(\n",
    "            emb_matrix, freeze=config[\"freeze\"], padding_idx=vocab.PAD_IDX\n",
    "        )\n",
    "        cell_types = {\"RNN\": RNN, \"GRU\": GRU, \"LSTM\": LSTM}\n",
    "        cell_class = cell_types[config[\"cell_type\"]]\n",
    "        self.cell = cell_class(\n",
    "            input_size=emb_matrix.size(1),\n",
    "            batch_first=True,\n",
    "            hidden_size=config[\"hidden_size\"],\n",
    "            num_layers=config[\"num_layers\"],\n",
    "            dropout=config[\"cell_dropout\"],\n",
    "            bidirectional=config[\"bidirectional\"],\n",
    "        )\n",
    "        activation_types = {\n",
    "            \"sigmoid\": sigmoid,\n",
    "            \"tanh\": tanh,\n",
    "            \"relu\": relu,\n",
    "            \"elu\": elu,\n",
    "        }\n",
    "        self.out_activation = activation_types[config[\"out_activation\"]]\n",
    "        self.out_dropout = Dropout(config[\"out_dropout\"])\n",
    "        cur_out_size = config[\"hidden_size\"] * config[\"num_layers\"]\n",
    "        if config[\"bidirectional\"]:\n",
    "            cur_out_size *= 2\n",
    "        out_layers = []\n",
    "        for cur_hidden_size in config[\"out_sizes\"]:\n",
    "            out_layers.append(Linear(cur_out_size, cur_hidden_size))\n",
    "            cur_out_size = cur_hidden_size\n",
    "        out_layers.append(Linear(cur_out_size, 6))\n",
    "        self.out_proj = Sequential(*out_layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embeddings(input.data)\n",
    "        _, last_state = self.cell(\n",
    "            PackedSequence(\n",
    "                embedded,\n",
    "                input.batch_sizes,\n",
    "                sorted_indices=input.sorted_indices,\n",
    "                unsorted_indices=input.unsorted_indices,\n",
    "            )\n",
    "        )\n",
    "        if isinstance(last_state, tuple):\n",
    "            last_state = last_state[0]\n",
    "        last_state = last_state.transpose(0, 1)\n",
    "        last_state = last_state.reshape(last_state.size(0), -1)\n",
    "        return self.out_proj(last_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Тренер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "from numpy import asarray\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from model import RecurrentClassifier\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, config: Dict):\n",
    "        \"\"\"\n",
    "        Fits end evaluates given model with Adam optimizer.\n",
    "        Hyperparameters are specified in `config`\n",
    "        Possible keys are:\n",
    "            - n_epochs: number of epochs to train\n",
    "            - lr: optimizer learning rate\n",
    "            - weight_decay: l2 regularization weight\n",
    "            - device: on which device to perform training (\"cpu\" or \"cuda\")\n",
    "            - verbose: whether to print anything during training\n",
    "        :param config: configuration for `Trainer`\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.n_epochs = config[\"n_epochs\"]\n",
    "        self.setup_opt_fn = lambda model: Adam(\n",
    "            model.parameters(), config[\"lr\"], weight_decay=config[\"weight_decay\"]\n",
    "        )\n",
    "        self.model = None\n",
    "        self.opt = None\n",
    "        self.history = None\n",
    "        self.loss_fn = CrossEntropyLoss()\n",
    "        self.device = config[\"device\"]\n",
    "        self.verbose = config.get(\"verbose\", True)\n",
    "\n",
    "    def fit(self, model, train_loader, val_loader):\n",
    "        \"\"\"\n",
    "        Fits model on training data, each epoch evaluates on validation data\n",
    "        :param model: PyTorch model for toxic comments classification (for example, `RecurrentClassifier`)\n",
    "        :param train_loader: DataLoader for training data\n",
    "        :param val_loader: DataLoader for validation data\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.model = model.to(self.device)\n",
    "        self.opt = self.setup_opt_fn(self.model)\n",
    "        self.history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "        for epoch in range(self.n_epochs):\n",
    "            print(f\"Epoch {epoch + 1}/{self.n_epochs}\")\n",
    "            train_info = self._train_epoch(train_loader)\n",
    "            val_info = self._val_epoch(val_loader)\n",
    "            self.history[\"train_loss\"].extend(train_info[\"train_loss\"])\n",
    "            self.history[\"val_loss\"].append(val_info[\"loss\"])\n",
    "            self.history[\"val_acc\"].append(val_info[\"acc\"])\n",
    "        return self.model.eval()\n",
    "\n",
    "    def _train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "        if self.verbose:\n",
    "            train_loader = tqdm(train_loader)\n",
    "        for batch in train_loader:\n",
    "            self.model.zero_grad()\n",
    "            texts, labels = batch\n",
    "            logits = self.model.forward(texts.to(self.device))\n",
    "            loss = self.loss_fn(logits, labels.to(self.device))\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "            loss_val = loss.item()\n",
    "            if self.verbose:\n",
    "                train_loader.set_description(f\"Loss={loss_val:.3}\")\n",
    "            losses.append(loss_val)\n",
    "        return {\"train_loss\": losses}\n",
    "\n",
    "    def _val_epoch(self, val_loader):\n",
    "        self.model.eval()\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        if self.verbose:\n",
    "            val_loader = tqdm(val_loader)\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                texts, labels = batch\n",
    "                logits = self.model.forward(texts.to(self.device))\n",
    "                all_logits.append(logits)\n",
    "                all_labels.append(labels)\n",
    "        all_labels = torch.cat(all_labels).to(self.device)\n",
    "        all_logits = torch.cat(all_logits)\n",
    "        loss = CrossEntropyLoss()(all_logits, all_labels).item()\n",
    "        acc = (all_logits.argmax(1) == all_labels).float().mean().item()\n",
    "        if self.verbose:\n",
    "            val_loader.set_description(f\"Loss={loss:.3}; Acc:{acc:.3}\")\n",
    "        return {\"acc\": acc, \"loss\": loss}\n",
    "\n",
    "    def predict(self, test_loader):\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"You should train the model first\")\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                texts, labels = batch\n",
    "                logits = self.model.forward(texts.to(self.device))\n",
    "                predictions.extend(logits.argmax(1).tolist())\n",
    "        return asarray(predictions)\n",
    "\n",
    "    def save(self, path: str):\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"You should train the model first\")\n",
    "        checkpoint = {\n",
    "            \"config\": self.model.config,\n",
    "            \"trainer_config\": self.config,\n",
    "            \"vocab\": self.model.vocab,\n",
    "            \"emb_matrix\": self.model.emb_matrix,\n",
    "            \"state_dict\": self.model.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, path)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path: str):\n",
    "        ckpt = torch.load(path)\n",
    "        keys = [\"config\", \"trainer_config\",\n",
    "                \"vocab\", \"emb_matrix\", \"state_dict\"]\n",
    "        for key in keys:\n",
    "            if key not in ckpt:\n",
    "                raise RuntimeError(f\"Missing key {key} in checkpoint\")\n",
    "        new_model = RecurrentClassifier(\n",
    "            ckpt[\"config\"], ckpt[\"vocab\"], ckpt[\"emb_matrix\"]\n",
    "        )\n",
    "        new_model.load_state_dict(ckpt[\"state_dict\"])\n",
    "        new_trainer = cls(ckpt[\"trainer_config\"])\n",
    "        new_trainer.model = new_model\n",
    "        new_trainer.model.to(new_trainer.device)\n",
    "        return new_trainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выполнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer()\n",
    "tok_texts = [tok.tokenize(t) for t in train_data['clear_text'].values]\n",
    "vocab = Vocab(tok_texts, max_vocab_size=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels, val_texts, val_labels = train_test_split(train_data)\n",
    "\n",
    "train_dataset = TextDataset([tok.tokenize(t)\n",
    "                            for t in train_texts], train_labels, vocab)\n",
    "val_dataset = TextDataset([tok.tokenize(t)\n",
    "                          for t in val_texts], val_labels, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Путь к модели\n",
    "path_to_model = DATA_PATH + '65/model.bin'\n",
    "\n",
    "# Загрузка предварительно обученной модели (может потребовать много времени и памяти)\n",
    "word_vectors = KeyedVectors.load_word2vec_format(path_to_model, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GENSIM_DATA_DIR\"] = str(Path.cwd())\n",
    "gensim_model = api.load(\"word2vec-ruscorpora-300\")\n",
    "emb_matrix = prepare_emb_matrix(word_vectors, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"freeze\": True,\n",
    "    \"cell_type\": \"LSTM\",\n",
    "    \"cell_dropout\": 0.2,\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_size\": 256,\n",
    "    \"out_activation\": \"relu\",\n",
    "    \"bidirectional\": True,\n",
    "    \"out_dropout\": 0.1,\n",
    "    \"out_sizes\": [200],\n",
    "}\n",
    "\n",
    "trainer_config = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"n_epochs\": 10,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"batch_size\": 128,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "clf_model = RecurrentClassifier(config, vocab, emb_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe98b861e5cc46fa93e45fbdf4f5151b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a840d8724a42c1939a3f13b0ca174d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05b96a39d394a11842ffdad2e60e89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c158f9b63b774c5fb39699a00d325c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ac2897ba9b46fc9695eaeabb90fffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed61faffcdd64b069741263d85d6ec9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24a90054ea94cb28498c528b474681f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39802de3ba5a494bb41549e905f24d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e533fec04ca4ebcac6a2c8fe5faafbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b88d7c970fe4b89b0d476c7bb913536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c7958373974f39bb68905b88c66a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb184a9bdc3849c690fcb9ed1481a00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ad1b5bd2404138a15d4b395b82b465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3dee0d264c46289fc1159a24e163fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b8904089474a6fb5ccc7246e67d22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ceddd75e544257b6063ae52705a0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ede633e71844f6daa268b5883cf2f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853c9c4adbdd4470ac5c2fce0f9e2f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47f602403554f13b2ee5dfff8d55bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19d085c2b60480d8a0c73154530c418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RecurrentClassifier(\n",
       "  (embeddings): Embedding(22411, 100, padding_idx=0)\n",
       "  (cell): LSTM(100, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (out_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (out_proj): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
       "    (1): Linear(in_features=200, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=trainer_config[\"batch_size\"],\n",
    "                              shuffle=True,\n",
    "                              num_workers=0,\n",
    "                              collate_fn=train_dataset.collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            batch_size=trainer_config[\"batch_size\"],\n",
    "                            shuffle=False,\n",
    "                            num_workers=0,\n",
    "                            collate_fn=val_dataset.collate_fn)\n",
    "t = Trainer(trainer_config)\n",
    "t.fit(clf_model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save(\"baseline_model.ckpt\")\n",
    "t = Trainer.load(\"baseline_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text):\n",
    "    tok_text = tok.tokenize(text)\n",
    "    indexed_text = torch.tensor(vocab.vectorize(tok_text)).to(t.device)\n",
    "    genre = model(pack_sequence([indexed_text])).argmax().item()\n",
    "    return genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(TextDataset([tok.tokenize(t) for t in test_data['clear_text'].values], [-1] * test_data.shape[0], vocab),\n",
    "                             batch_size=trainer_config[\"batch_size\"],\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             collate_fn=val_dataset.collate_fn)\n",
    "\n",
    "predictions = t.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 1, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(os.path.join(DATA_PATH, \"sample_submission.csv\"))\n",
    "# pred_labels = le.inverse_transform(predictions)\n",
    "sample_submission[\"rate\"] = predictions\n",
    "sample_submission.loc[sample_submission['rate'] == 5, 'rate'] = 4\n",
    "sample_submission['rate'] = sample_submission['rate'].apply(lambda a: a + 1)\n",
    "\n",
    "sample_submission['rate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(DATA_PATH+\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
