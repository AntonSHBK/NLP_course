{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# путь к data\n",
    "DATA_PATH = \"../../data/task_2/\"\n",
    "# Глобальное значение \"random_state\" \n",
    "STATE = 42\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns in the train data set: (48665, 3)\n",
      "Number of rows and columns in the valid data set: (12167, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>text</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Очень понравилось. Были в начале марта  с соба...</td>\n",
       "      <td>очень понравиться начало март собака дойти лес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом магазин устраивает.\\nАссортимент позво...</td>\n",
       "      <td>целое магазин устраивать ассортимент позволять...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Очень хорошо что открылась 5 ка, теперь не над...</td>\n",
       "      <td>очень открыться ка далеко ехать рядом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Пятёрочка громко объявила о том как она заботи...</td>\n",
       "      <td>пята рочко громко объявить заботиться пенсионе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Тесно, вечная сутолока, между рядами трудно ра...</td>\n",
       "      <td>тесно вечный сутолока ряд трудно разойтись гря...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate                                               text  \\\n",
       "0     3  Очень понравилось. Были в начале марта  с соба...   \n",
       "1     4  В целом магазин устраивает.\\nАссортимент позво...   \n",
       "2     4  Очень хорошо что открылась 5 ка, теперь не над...   \n",
       "3     2  Пятёрочка громко объявила о том как она заботи...   \n",
       "4     2  Тесно, вечная сутолока, между рядами трудно ра...   \n",
       "\n",
       "                                          clear_text  \n",
       "0  очень понравиться начало март собака дойти лес...  \n",
       "1  целое магазин устраивать ассортимент позволять...  \n",
       "2              очень открыться ка далеко ехать рядом  \n",
       "3  пята рочко громко объявить заботиться пенсионе...  \n",
       "4  тесно вечный сутолока ряд трудно разойтись гря...  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(DATA_PATH, \"test.csv\"))\n",
    "\n",
    "print(\"Number of rows and columns in the train data set:\", train_data.shape)\n",
    "print(\"Number of rows and columns in the valid data set:\", test_data.shape)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48665 entries, 0 to 48664\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   rate        48665 non-null  int64 \n",
      " 1   text        48665 non-null  object\n",
      " 2   clear_text  48543 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['rate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['rate'].hist(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>text</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Очень понравилось. Были в начале марта  с соба...</td>\n",
       "      <td>очень понравиться начало март собака дойти лес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом магазин устраивает.\\nАссортимент позво...</td>\n",
       "      <td>целое магазин устраивать ассортимент позволять...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Очень хорошо что открылась 5 ка, теперь не над...</td>\n",
       "      <td>очень открыться ка далеко ехать рядом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Пятёрочка громко объявила о том как она заботи...</td>\n",
       "      <td>пята рочко громко объявить заботиться пенсионе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Тесно, вечная сутолока, между рядами трудно ра...</td>\n",
       "      <td>тесно вечный сутолока ряд трудно разойтись гря...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate                                               text  \\\n",
       "0     3  Очень понравилось. Были в начале марта  с соба...   \n",
       "1     4  В целом магазин устраивает.\\nАссортимент позво...   \n",
       "2     4  Очень хорошо что открылась 5 ка, теперь не над...   \n",
       "3     2  Пятёрочка громко объявила о том как она заботи...   \n",
       "4     2  Тесно, вечная сутолока, между рядами трудно ра...   \n",
       "\n",
       "                                          clear_text  \n",
       "0  очень понравиться начало март собака дойти лес...  \n",
       "1  целое магазин устраивать ассортимент позволять...  \n",
       "2              очень открыться ка далеко ехать рядом  \n",
       "3  пята рочко громко объявить заботиться пенсионе...  \n",
       "4  тесно вечный сутолока ряд трудно разойтись гря...  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "train_data['rate'] = le.fit_transform(train_data['rate'])\n",
    "\n",
    "# Оптимизация типов данных\n",
    "train_data['rate'] = train_data['rate'].astype('uint8')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48665 entries, 0 to 48664\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   rate        48665 non-null  uint8 \n",
      " 1   text        48665 non-null  object\n",
      " 2   clear_text  48543 non-null  object\n",
      "dtypes: object(2), uint8(1)\n",
      "memory usage: 808.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import pymorphy2\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Загрузка русских стоп-слов\n",
    "nltk.download('stopwords')\n",
    "russian_stopwords = stopwords.words('russian')\n",
    "\n",
    "# Инициализация анализатора pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "# Инициализируем стеммер\n",
    "stemmer = SnowballStemmer('russian')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Удаление лишних символов и нормализация\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Удаление знаков пунктуации\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n",
    "    \n",
    "    # Дополнительно: удаление специальных символов или любых символов, кроме букв (латиница или кириллица)\n",
    "    text = re.sub(r\"[^a-zA-Zа-яА-Я\\s]\", \" \", text)\n",
    "\n",
    "    # Удаление множество пробелов\n",
    "    text = text.replace(r'\\s+','')\n",
    "    \n",
    "    \n",
    "    # Токенизация\n",
    "    tokens = word_tokenize(text, language=\"russian\")\n",
    "    \n",
    "    # Удаление стоп-слов и лемматизация\n",
    "    words_lemmatized = [morph.parse(word)[0].normal_form for word in tokens if word not in russian_stopwords]\n",
    "    \n",
    "    # Удаление стоп-слов и стемминг\n",
    "    # words_stemmed = [stemmer.stem(word) for word in words if word not in russian_stopwords]\n",
    "    \n",
    "    return ' '.join(words_lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['clear_text'] = train_data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data['clear_text'] = train_data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class FiveDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_seq_len):\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe['text'].tolist()\n",
    "        self.targets = None\n",
    "        if 'rate' in dataframe:\n",
    "            self.targets = dataframe['rate'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_seq_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        if self.targets is not None:\n",
    "            return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'targets': torch.tensor(self.targets[index], dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "class ModelForClassification(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, model_path: str, config: Dict):\n",
    "        super(ModelForClassification, self).__init__()\n",
    "        self.model_name = model_path\n",
    "        self.config = config\n",
    "        self.n_classes = config['num_classes']\n",
    "        self.dropout_rate = config['dropout_rate']\n",
    "        self.bert = AutoModel.from_pretrained(self.model_name)\n",
    "        self.pre_classifier = torch.nn.Linear(312, 768)\n",
    "        self.dropout = torch.nn.Dropout(self.dropout_rate)\n",
    "        self.classifier = torch.nn.Linear(768, self.n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask,):\n",
    "        output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        hidden_state = output[0]\n",
    "        hidden_state = hidden_state[:, 0]\n",
    "        hidden_state = self.pre_classifier(hidden_state)\n",
    "        hidden_state = torch.nn.ReLU()(hidden_state)\n",
    "        hidden_state = self.dropout(hidden_state)\n",
    "        output = self.classifier(hidden_state)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Тренер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "from numpy import asarray\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.n_epochs = config['n_epochs']\n",
    "        self.optimizer = None\n",
    "        self.opt_fn = lambda model: Adam(model.parameters(), config['lr'])\n",
    "        self.model: ModelForClassification = None\n",
    "        self.history = None\n",
    "        self.loss_fn = CrossEntropyLoss()\n",
    "        self.device = config['device']\n",
    "        self.verbose = config.get('verbose', True)\n",
    "\n",
    "    def fit(self, model, train_dataloader, val_dataloader):\n",
    "        self.model = model.to(self.device)\n",
    "        self.optimizer = self.opt_fn(model)\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': []\n",
    "        }\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            print(f\"Epoch {epoch + 1}/{self.n_epochs}\")\n",
    "            train_info = self.train_epoch(train_dataloader)\n",
    "            val_info = self.val_epoch(val_dataloader)\n",
    "            self.history['train_loss'].extend(train_info['loss'])\n",
    "            self.history['val_loss'].extend([val_info['loss']])\n",
    "            self.history['val_acc'].extend([val_info['acc']])\n",
    "        return self.model.eval()\n",
    "\n",
    "    def train_epoch(self, train_dataloader):\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "        if self.verbose:\n",
    "            train_dataloader = tqdm(train_dataloader)\n",
    "        for batch in train_dataloader:\n",
    "            ids = batch['ids'].to(self.device, dtype=torch.long)\n",
    "            mask = batch['mask'].to(self.device, dtype=torch.long)\n",
    "            targets = batch['targets'].to(self.device, dtype=torch.long)\n",
    "\n",
    "            outputs = self.model(ids, mask)\n",
    "            loss = self.loss_fn(outputs, targets)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            loss_val = loss.item()\n",
    "            if self.verbose:\n",
    "                train_dataloader.set_description(f\"Loss={loss_val:.3}\")\n",
    "            losses.append(loss_val)\n",
    "        return {'loss': losses}\n",
    "\n",
    "    def val_epoch(self, val_dataloader):\n",
    "        self.model.eval()\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        if self.verbose:\n",
    "            val_dataloader = tqdm(val_dataloader)\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                ids = batch['ids'].to(self.device, dtype=torch.long)\n",
    "                mask = batch['mask'].to(self.device, dtype=torch.long)\n",
    "                targets = batch['targets'].to(self.device, dtype=torch.long)\n",
    "                outputs = self.model(ids, mask)\n",
    "                all_logits.append(outputs)\n",
    "                all_labels.append(targets)\n",
    "        all_labels = torch.cat(all_labels).to(self.device)\n",
    "        all_logits = torch.cat(all_logits).to(self.device)\n",
    "        loss = self.loss_fn(all_logits, all_labels).item()\n",
    "        acc = (all_logits.argmax(1) == all_labels).float().mean().item()\n",
    "        print(acc)\n",
    "        if self.verbose:\n",
    "            val_dataloader.set_description(f\"Loss={loss:.3}; Acc:{acc:.3}\")\n",
    "        return {\n",
    "            'acc': acc,\n",
    "            'loss': loss\n",
    "        }\n",
    "\n",
    "    def predict(self, test_dataloader):\n",
    "        if not self.model:\n",
    "            raise RuntimeError(\"You should train the model first\")\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_dataloader:\n",
    "                ids = batch['ids'].to(self.device, dtype=torch.long)\n",
    "                mask = batch['mask'].to(self.device, dtype=torch.long)\n",
    "                outputs = self.model(ids, mask)\n",
    "                predictions.extend(outputs.argmax(1).tolist())\n",
    "        return asarray(predictions)\n",
    "\n",
    "    def save(self, path: str):\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"You should train the model first\")\n",
    "        checkpoint = {\n",
    "            \"config\": self.model.config,\n",
    "            \"trainer_config\": self.config,\n",
    "            \"model_name\": self.model.model_name,\n",
    "            \"model_state_dict\": self.model.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, path)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path: str):\n",
    "        ckpt = torch.load(path)\n",
    "        keys = [\"config\", \"trainer_config\", \"model_state_dict\"]\n",
    "        for key in keys:\n",
    "            if key not in ckpt:\n",
    "                raise RuntimeError(f\"Missing key {key} in checkpoint\")\n",
    "        new_model = ModelForClassification(\n",
    "            ckpt['model_name'],\n",
    "            ckpt[\"config\"]\n",
    "        )\n",
    "        new_model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "        new_trainer = cls(ckpt[\"trainer_config\"])\n",
    "        new_trainer.model = new_model\n",
    "        new_trainer.model.to(new_trainer.device)\n",
    "        return new_trainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выполнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_small = train_data[['text', 'rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, val_split = train_test_split(train_data, test_size=0.2, random_state=42, stratify=train_data['rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"cointegrated/rubert-tiny2\", truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FiveDataset(train_split, tokenizer, MAX_LEN)\n",
    "val_dataset = FiveDataset(val_split, tokenizer, MAX_LEN)\n",
    "test_dataset = FiveDataset(test_data, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\"batch_size\": BATCH_SIZE,\n",
    "                \"shuffle\": True,\n",
    "                \"num_workers\": 0\n",
    "                }\n",
    "\n",
    "test_params = {\"batch_size\": BATCH_SIZE,\n",
    "               \"shuffle\": False,\n",
    "               \"num_workers\": 0\n",
    "               }\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, **train_params)\n",
    "val_dataloader = DataLoader(val_dataset, **test_params)\n",
    "test_dataloader = DataLoader(test_dataset, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_classes\": 5,\n",
    "    \"dropout_rate\": 0.1\n",
    "}\n",
    "model = ModelForClassification(\n",
    "    \"cointegrated/rubert-tiny2\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"n_epochs\": 5,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"seed\": 42,\n",
    "}\n",
    "t = Trainer(trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92b957e69554617b0dcdd941e0ac0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\NLP_course\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7c5362d3154808b2125d1745e2f369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6558101177215576\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8047ea9fb9474dee919cdcb61b765d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3744c4078344a31b761522d66c06658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6499537825584412\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68507415d06a4966b2303e7c50d12d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7403aed15f6c434a84653d5d015c4b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6445083618164062\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2388f916d0342889c62d2c5a2a37833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3343920b9f3d44368f0e937a3a815813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6207746863365173\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e032c499e8724a1ab09895ed0e967b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[186], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[178], line 33\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloader, val_dataloader)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     train_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     val_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_epoch(val_dataloader)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(train_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[178], line 54\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[1;34m(self, train_dataloader)\u001b[0m\n\u001b[0;32m     51\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(outputs, targets)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 54\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     56\u001b[0m loss_val \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\Projects\\NLP_course\\.venv\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\NLP_course\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t.fit(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save(DATA_PATH+\"baseline_model.ckpt\")\n",
    "t = Trainer.load(DATA_PATH+\"baseline_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = t.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 1, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(os.path.join(DATA_PATH, \"sample_submission.csv\"))\n",
    "pred_labels = le.inverse_transform(predictions)\n",
    "sample_submission[\"rate\"] = predictions\n",
    "sample_submission['rate'] = le.inverse_transform(sample_submission['rate'])\n",
    "\n",
    "# sample_submission.loc[sample_submission['rate'] == 5, 'rate'] = 4\n",
    "sample_submission['rate'] = sample_submission['rate'].apply(lambda a: a + 1)\n",
    "\n",
    "sample_submission['rate'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  rate\n",
       "0      0     5\n",
       "1      1     4\n",
       "2      2     5\n",
       "3      3     4\n",
       "4      4     1"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(DATA_PATH+\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
