{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = Path('../docs/imgs/')\n",
    "DATA_PATH = Path('../data/project/')\n",
    "\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    random.seed(seed)\n",
    "\n",
    "seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uu import encode\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(file_path: Path) -> pd.DataFrame:\n",
    "    data = pd.read_excel(file_path)    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns in the train data set: (11475, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\NLP_course\\.venv\\lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    }
   ],
   "source": [
    "dataframe = load_data(os.path.join(DATA_PATH, \"data_1.xlsx\"))\n",
    "print(\"Number of rows and columns in the train data set:\", dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>responsible_person</th>\n",
       "      <th>type_problem</th>\n",
       "      <th>topic</th>\n",
       "      <th>categoria</th>\n",
       "      <th>region</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Администрация Химки</td>\n",
       "      <td>Устранение проблемы</td>\n",
       "      <td>Неудовлетворительное качество товара, оказания...</td>\n",
       "      <td>Торговля, товары и услуги</td>\n",
       "      <td>Орехово-Зуевский</td>\n",
       "      <td>Цифровизация услуг в любых сферах, а особенно ...</td>\n",
       "      <td>Здравствуйте! На трубопроводе центрального ото...</td>\n",
       "      <td>[id181153628|Ольга], совершенно верно! Каждый...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Администрация Химки</td>\n",
       "      <td>Устранение проблемы</td>\n",
       "      <td>Неудовлетворительное качество товара, оказания...</td>\n",
       "      <td>Торговля, товары и услуги</td>\n",
       "      <td>Орехово-Зуевский</td>\n",
       "      <td>Цифровизация услуг в любых сферах, а особенно ...</td>\n",
       "      <td>Здравствуйте! Специалисты ТСК \"Мосэнерго\" пров...</td>\n",
       "      <td>[id181153628|Ольга], совершенно верно! Каждый...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    responsible_person         type_problem  \\\n",
       "0  Администрация Химки  Устранение проблемы   \n",
       "1  Администрация Химки  Устранение проблемы   \n",
       "\n",
       "                                               topic  \\\n",
       "0  Неудовлетворительное качество товара, оказания...   \n",
       "1  Неудовлетворительное качество товара, оказания...   \n",
       "\n",
       "                   categoria            region  \\\n",
       "0  Торговля, товары и услуги  Орехово-Зуевский   \n",
       "1  Торговля, товары и услуги  Орехово-Зуевский   \n",
       "\n",
       "                                              source  \\\n",
       "0  Цифровизация услуг в любых сферах, а особенно ...   \n",
       "1  Цифровизация услуг в любых сферах, а особенно ...   \n",
       "\n",
       "                                              target  \\\n",
       "0  Здравствуйте! На трубопроводе центрального ото...   \n",
       "1  Здравствуйте! Специалисты ТСК \"Мосэнерго\" пров...   \n",
       "\n",
       "                                             context  \n",
       "0   [id181153628|Ольга], совершенно верно! Каждый...  \n",
       "1   [id181153628|Ольга], совершенно верно! Каждый...  "
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11475 entries, 0 to 11474\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   responsible_person  11475 non-null  object\n",
      " 1   type_problem        11475 non-null  object\n",
      " 2   topic               11475 non-null  object\n",
      " 3   categoria           11475 non-null  object\n",
      " 4   region              11475 non-null  object\n",
      " 5   source              11150 non-null  object\n",
      " 6   target              11465 non-null  object\n",
      " 7   context             11475 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 717.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>responsible_person</th>\n",
       "      <th>type_problem</th>\n",
       "      <th>topic</th>\n",
       "      <th>categoria</th>\n",
       "      <th>region</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11475</td>\n",
       "      <td>11475</td>\n",
       "      <td>11475</td>\n",
       "      <td>11475</td>\n",
       "      <td>11475</td>\n",
       "      <td>11150</td>\n",
       "      <td>11465</td>\n",
       "      <td>11475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>181</td>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>11</td>\n",
       "      <td>56</td>\n",
       "      <td>5534</td>\n",
       "      <td>9821</td>\n",
       "      <td>5694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Александр Αлексеев</td>\n",
       "      <td>Устранение проблемы</td>\n",
       "      <td>-</td>\n",
       "      <td>ЖКХ</td>\n",
       "      <td>Другие регионы</td>\n",
       "      <td>Это ситуация в доме 15/2 - результат полного о...</td>\n",
       "      <td>Здравствуйте! Спасибо за Ваш вопрос. В микрора...</td>\n",
       "      <td>[id4847589|Александр], кто ответит за нанесён...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>717</td>\n",
       "      <td>8365</td>\n",
       "      <td>1663</td>\n",
       "      <td>4848</td>\n",
       "      <td>2513</td>\n",
       "      <td>24</td>\n",
       "      <td>111</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        responsible_person         type_problem  topic categoria  \\\n",
       "count                11475                11475  11475     11475   \n",
       "unique                 181                   11    120        11   \n",
       "top     Александр Αлексеев  Устранение проблемы      -       ЖКХ   \n",
       "freq                   717                 8365   1663      4848   \n",
       "\n",
       "                region                                             source  \\\n",
       "count            11475                                              11150   \n",
       "unique              56                                               5534   \n",
       "top     Другие регионы  Это ситуация в доме 15/2 - результат полного о...   \n",
       "freq              2513                                                 24   \n",
       "\n",
       "                                                   target  \\\n",
       "count                                               11465   \n",
       "unique                                               9821   \n",
       "top     Здравствуйте! Спасибо за Ваш вопрос. В микрора...   \n",
       "freq                                                  111   \n",
       "\n",
       "                                                  context  \n",
       "count                                               11475  \n",
       "unique                                               5694  \n",
       "top      [id4847589|Александр], кто ответит за нанесён...  \n",
       "freq                                                   24  "
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11140 entries, 0 to 11474\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   responsible_person  11140 non-null  object\n",
      " 1   type_problem        11140 non-null  object\n",
      " 2   topic               11140 non-null  object\n",
      " 3   categoria           11140 non-null  object\n",
      " 4   region              11140 non-null  object\n",
      " 5   source              11140 non-null  object\n",
      " 6   target              11140 non-null  object\n",
      " 7   context             11140 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 783.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe = dataframe.dropna(subset=['target', 'source'])\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодирование меток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список категорий в 'categoria': ['Благодарности' 'Комментарии' 'Критика власти' 'Неопределенное сообщение'\n",
      " 'Ответы' 'Повторная жалоба' 'Предложение/инициатива/идея'\n",
      " 'Просьба проинформировать' 'Семьи военнослужащих' 'Соболезнования'\n",
      " 'Устранение проблемы']\n",
      "['Устранение проблемы']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "work_dataframe = dataframe.copy()\n",
    "\n",
    "class CategoricalLabelEncoder():\n",
    "    def __init__(self, dataframe: pd.DataFrame, categorical_columns: list[str]) -> None:\n",
    "        self.encoders = {}\n",
    "        \n",
    "        for column in categorical_columns:\n",
    "            encoder = LabelEncoder()\n",
    "            dataframe[column] = encoder.fit_transform(dataframe[column])\n",
    "            self.encoders[column] = encoder\n",
    "        \n",
    "    def decode(self, label: str, code: list[int]):\n",
    "        return self.encoders[label].inverse_transform([code])\n",
    "    \n",
    "    def get_classes(self, label):\n",
    "        categories_list = self.encoders[label].classes_\n",
    "        print(\"Список категорий в 'categoria':\", categories_list)\n",
    "        return categories_list\n",
    "\n",
    "categorical_columns = ['responsible_person', 'type_problem', 'topic', 'categoria', 'region']\n",
    "datafarme_encoders = CategoricalLabelEncoder(work_dataframe, categorical_columns)\n",
    "\n",
    "datafarme_encoders.get_classes('type_problem')\n",
    "\n",
    "print(datafarme_encoders.decode('type_problem', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>responsible_person</th>\n",
       "      <th>type_problem</th>\n",
       "      <th>topic</th>\n",
       "      <th>categoria</th>\n",
       "      <th>region</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>79</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>Цифровизация услуг в любых сферах, а особенно ...</td>\n",
       "      <td>Здравствуйте! На трубопроводе центрального ото...</td>\n",
       "      <td>[id181153628|Ольга], совершенно верно! Каждый...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>79</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>Цифровизация услуг в любых сферах, а особенно ...</td>\n",
       "      <td>Здравствуйте! Специалисты ТСК \"Мосэнерго\" пров...</td>\n",
       "      <td>[id181153628|Ольга], совершенно верно! Каждый...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>79</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>Цифровизация услуг в любых сферах, а особенно ...</td>\n",
       "      <td>Здравствуйте! Конкретизируйте, пожалуйста, Ваш...</td>\n",
       "      <td>[id181153628|Ольга], совершенно верно! Каждый...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>79</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>Цифровизация услуг в любых сферах, а особенно ...</td>\n",
       "      <td>Здравствуйте! Спасибо за Ваш вопрос. В микрора...</td>\n",
       "      <td>[id181153628|Ольга], совершенно верно! Каждый...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   responsible_person  type_problem  topic  categoria  region  \\\n",
       "0                  30            10     79          9      34   \n",
       "1                  30            10     79          9      34   \n",
       "2                  30            10     79          9      34   \n",
       "3                  30            10     79          9      34   \n",
       "\n",
       "                                              source  \\\n",
       "0  Цифровизация услуг в любых сферах, а особенно ...   \n",
       "1  Цифровизация услуг в любых сферах, а особенно ...   \n",
       "2  Цифровизация услуг в любых сферах, а особенно ...   \n",
       "3  Цифровизация услуг в любых сферах, а особенно ...   \n",
       "\n",
       "                                              target  \\\n",
       "0  Здравствуйте! На трубопроводе центрального ото...   \n",
       "1  Здравствуйте! Специалисты ТСК \"Мосэнерго\" пров...   \n",
       "2  Здравствуйте! Конкретизируйте, пожалуйста, Ваш...   \n",
       "3  Здравствуйте! Спасибо за Ваш вопрос. В микрора...   \n",
       "\n",
       "                                             context  \n",
       "0   [id181153628|Ольга], совершенно верно! Каждый...  \n",
       "1   [id181153628|Ольга], совершенно верно! Каждый...  \n",
       "2   [id181153628|Ольга], совершенно верно! Каждый...  \n",
       "3   [id181153628|Ольга], совершенно верно! Каждый...  "
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_dataframe.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 dataframe: pd.DataFrame,\n",
    "                 tokenizer: GPT2Tokenizer,\n",
    "                 max_length=512):\n",
    "        \n",
    "        self.dataframe = dataframe\n",
    "        \n",
    "        self.type_ids = torch.tensor(\n",
    "            dataframe['type_problem'].astype(int).tolist()\n",
    "        )\n",
    "\n",
    "        self.source_encodings = tokenizer(\n",
    "            dataframe['source'].tolist(), \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=max_length, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        self.target_encodings = tokenizer(\n",
    "            dataframe['target'].tolist(), \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=max_length, \n",
    "            return_tensors=\"pt\"\n",
    "        )      \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.type_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.source_encodings.items()}\n",
    "        item['target_ids'] = self.target_encodings['input_ids'][idx]\n",
    "        item['target_attention_mask'] = self.target_encodings['attention_mask'][idx]\n",
    "        item['type_ids'] = self.type_ids[idx]\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель\n",
    "В модели `CustomGPT2Model` логиты будут иметь размеры зависящие от следующих факторов:\n",
    "\n",
    "1. **Количество токенов в входной последовательности**: Обозначим количество токенов как `T`. Это количество токенов, которое вы подаете в модель в `input_ids`. Также это число будет равно длине последовательности, которая используется для генерации выхода.\n",
    "\n",
    "2. **Размер словаря модели GPT-2**: Обозначим размер словаря как `V`. Это количество уникальных токенов, которые модель может генерировать. Этот параметр зависит от конфигурации предобученной модели GPT-2, которую вы используете.\n",
    "\n",
    "### Размеры тензоров в вашей модели:\n",
    "\n",
    "- **`input_ids`**: Тензор размером `[B, T]`, где `B` — размер батча, `T` — количество токенов в каждой последовательности входных данных.\n",
    "\n",
    "- **`type_ids`**: Тензор размером `[B]`, содержащий идентификаторы типов сообщений для каждого элемента в батче. Этот тензор расширяется и повторяется, чтобы соответствовать длине `T`.\n",
    "\n",
    "- **`attention_mask`**: Тензор размером `[B, T]`, который указывает на то, какие токены являются значимыми для каждой последовательности.\n",
    "\n",
    "- **`combined_embeds` и `inputs_embeds`**: Тензоры размером `[B, T, H]`, где `H` — размер скрытого состояния в модели GPT-2.\n",
    "\n",
    "- **`logits`** после применения `lm_head`: Тензор размером `[B, T, V]`, где каждый элемент в тензоре представляет логиты для каждого токена в каждой последовательности батча для каждого возможного токена в словаре.\n",
    "\n",
    "### Как это работает в вашей `forward` функции:\n",
    "\n",
    "1. **Токен-встраивания** (`wte`) и **встраивания типа** комбинируются и проходят через линейный слой (`combined_linear`).\n",
    "\n",
    "2. **Встраивания** передаются в основную модель GPT-2, которая возвращает последние скрытые состояния.\n",
    "\n",
    "3. **Последние скрытые состояния** преобразуются в логиты с помощью `lm_head`, которые представляют собой вероятности следующего токена для каждого токена в последовательности.\n",
    "\n",
    "Таким образом, если вы передаете `input_ids` размером `[5, 5]` (5 последовательностей по 5 токенов каждая), вы получите `logits` размером `[5, 5, V]`, где `V` — размер словаря вашей модели GPT-2. Эти логиты используются для выбора следующего токена в процессе генерации текста или для вычисления потерь во время обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2Model\n",
    "\n",
    "class CustomGPT2Model(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        pretrained_model_name,\n",
    "        num_message_types,\n",
    "        data_path=Path('')\n",
    "    ):\n",
    "        super(CustomGPT2Model, self).__init__()\n",
    "        # Загрузка предобученной модели GPT-2\n",
    "        self.gpt2 = GPT2Model.from_pretrained(pretrained_model_name, cache_dir=data_path)\n",
    "        \n",
    "        # Слой для встраивания типа сообщения\n",
    "        self.type_embedding = nn.Embedding(num_message_types, self.gpt2.config.hidden_size)\n",
    "        \n",
    "        # Дополнительный линейный слой для объединения встраивания типа сообщения и токенов\n",
    "        self.combined_linear = nn.Linear(self.gpt2.config.hidden_size, self.gpt2.config.hidden_size)\n",
    "        # Дополнительный слой для логитов\n",
    "        self.lm_head = nn.Linear(self.gpt2.config.hidden_size, self.gpt2.config.vocab_size)  # Дополнительный слой для логитов\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, type_ids):\n",
    "        # Получение встраиваний токенов\n",
    "        inputs_embeds = self.gpt2.wte(input_ids)  # wte - word token embeddings\n",
    "        \n",
    "        # Получение встраивания для типа сообщения\n",
    "        type_embeds = self.type_embedding(type_ids).unsqueeze(1)  # Расширяем размерности для сложения\n",
    "        \n",
    "        # Сложение встраиваний токенов и типа по всей длине входа\n",
    "        combined_embeds = inputs_embeds + type_embeds.expand(-1, input_ids.size(1), -1)\n",
    "        \n",
    "        # Применяем дополнительный линейный слой\n",
    "        combined_embeds = self.combined_linear(combined_embeds)\n",
    "        \n",
    "        # Передача встраиваний в основную модель GPT-2\n",
    "        outputs = self.gpt2(inputs_embeds=combined_embeds, attention_mask=attention_mask)\n",
    "        \n",
    "        logits = self.lm_head(outputs.last_hidden_state)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plt_img(save_path, fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "        path = save_path / f\"{fig_id}.{fig_extension}\"\n",
    "        if tight_layout:\n",
    "            plt.tight_layout()\n",
    "        plt.savefig(path, format=fig_extension, dpi=resolution) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, tokenizer, weights={'bleu': 0.34, 'rouge': 0.33, 'meteor': 0.33}):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.weights = weights\n",
    "        self.rouge = Rouge()\n",
    "        \n",
    "        self.metrics = []\n",
    "\n",
    "    def evaluate(self, references: list, hypotheses: list):\n",
    "        tokenized_references = [[ref.split()] for ref in references]\n",
    "        tokenized_hypotheses = [hyp.split() for hyp in hypotheses]\n",
    "        \n",
    "        # Вычисление метрик BLEU, ROUGE, METEOR\n",
    "        bleu_score = corpus_bleu(tokenized_references, tokenized_hypotheses)\n",
    "        \n",
    "        rouge_score = self.rouge.get_scores(hypotheses, references, avg=True)['rouge-l']['f']\n",
    "        \n",
    "        list_meteor_score = [meteor_score(refs, hyp) for refs, hyp in zip(tokenized_references, tokenized_hypotheses)]\n",
    "        avg_meteor_score = np.mean(list_meteor_score)\n",
    "\n",
    "        # Словарь с результатами\n",
    "        results = {\n",
    "            'overall': self.weights['bleu'] * bleu_score +\n",
    "                       self.weights['rouge'] * rouge_score +\n",
    "                       self.weights['meteor'] * avg_meteor_score,\n",
    "            'bleu': bleu_score,\n",
    "            'rouge': rouge_score,\n",
    "            'meteor': avg_meteor_score\n",
    "        }\n",
    "        self.metrics.append(results)\n",
    "        return results\n",
    "    \n",
    "    def plot_metrics(self, imgs_path=Path('')):\n",
    "        epochs_range = range(1, len(self.metrics) + 1)\n",
    "        fig = plt.figure(figsize=(15, 6))  # Устанавливаем размер фигуры\n",
    "        \n",
    "        ax12 = plt.subplot(1, 2, 1)\n",
    "        ax12.plot(epochs_range, [m['overall'] for m in self.metrics], label='Overall Score', color='tab:green')\n",
    "        ax12.set_title('Overall Evaluation Score')\n",
    "        ax12.set_xlabel('Epochs')\n",
    "        ax12.set_ylabel('Score')\n",
    "        ax12.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        ax12.legend(loc='upper right')\n",
    "\n",
    "        # Отдельные графики для каждой метрики\n",
    "        ax21 = plt.subplot(1, 2, 2)\n",
    "        ax21.plot(epochs_range, [m['bleu'] for m in self.metrics], label='BLEU Score', color='tab:red')\n",
    "        ax21.plot(epochs_range, [m['rouge'] for m in self.metrics], label='ROUGE Score', color='tab:pink')\n",
    "        ax21.plot(epochs_range, [m['meteor'] for m in self.metrics], label='METEOR Score', color='tab:brown')\n",
    "        ax21.set_title('Individual Metrics')\n",
    "        ax21.set_xlabel('Epochs')\n",
    "        ax21.set_ylabel('Score')\n",
    "        ax21.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        ax21.legend(loc='upper right')      \n",
    "\n",
    "        fig.tight_layout()  # Убедимся, что макет не нарушен\n",
    "        save_plt_img(imgs_path, \"spacial_metrics\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конфиг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Config:\n",
    "    model_name = 'ai-forever/rugpt3small_based_on_gpt2'\n",
    "    max_length = 32\n",
    "    temperature=0.9\n",
    "    batch_size = 16\n",
    "    test_size=0.1\n",
    "    learning_rate = 1e-5\n",
    "    num_epochs = 3\n",
    "    uniq_name = 'custome_gpt2_model'\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: CustomGPT2Model, \n",
    "        evaluator: Evaluator, \n",
    "        tokenizer,\n",
    "        learning_rate=1e-3,\n",
    "        special_eval=False,\n",
    "        device='cpu',\n",
    "        imgs_path=Path(''),\n",
    "        config: Config=None\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.special_eval = special_eval\n",
    "        self.device = device\n",
    "        self.evaluator =  evaluator\n",
    "        self.tokenizer = tokenizer\n",
    "        self.imgs_path = imgs_path\n",
    "        self.config = config\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "        self.criterion = CrossEntropyLoss()\n",
    "        \n",
    "        # self.freeze_layers()\n",
    "        # self.print_freezed_layers()\n",
    "\n",
    "    def train(self, train_loader: DataLoader):\n",
    "        \"\"\"\n",
    "        Обучение модели\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        train_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, desc='Training', leave=True)\n",
    "        for batch in train_bar:\n",
    "            inputs_ids = batch['input_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            target_ids = batch['target_ids'].to(self.device)\n",
    "            type_ids = batch['type_ids'].to(self.device)\n",
    "            \n",
    "            logits = self.model(input_ids=inputs_ids, attention_mask=attention_mask, type_ids=type_ids)\n",
    "            loss = self.criterion(\n",
    "                logits.view(-1, self.model.gpt2.config.vocab_size),\n",
    "                target_ids.view(-1)\n",
    "            )\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_bar.set_postfix({'train loss': loss.item()})\n",
    "            \n",
    "        avg_loss = train_loss / len(train_loader)\n",
    "        self.train_losses.append(avg_loss)        \n",
    "        return avg_loss\n",
    "            \n",
    "\n",
    "    def eval(self, eval_loader: DataLoader):\n",
    "        self.model.eval()\n",
    "        eval_loss = 0\n",
    "        eval_bar = tqdm(eval_loader, desc=f'Evaluate', leave=True)\n",
    "        with torch.no_grad():\n",
    "            for batch in eval_bar:\n",
    "                inputs_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                target_ids = batch['target_ids'].to(self.device)\n",
    "                type_ids = batch['type_ids'].to(self.device)\n",
    "                \n",
    "                logits = self.model(input_ids=inputs_ids, attention_mask=attention_mask, type_ids=type_ids)\n",
    "\n",
    "                loss = self.criterion(\n",
    "                    logits.view(-1, self.model.gpt2.config.vocab_size),\n",
    "                    target_ids.view(-1)\n",
    "                )                          \n",
    "                eval_loss += loss.item()\n",
    "                eval_bar.set_postfix({'eval loss': loss.item()})\n",
    "                \n",
    "            avg_loss = eval_loss / len(eval_loader)\n",
    "            self.val_losses.append(avg_loss)    \n",
    "        \n",
    "        self.calculate_special_eval(eval_loader, self.config.max_length, self.config.temperature)\n",
    "        \n",
    "        return avg_loss\n",
    "            \n",
    "    def fit(self, epochs, train_loader: DataLoader, eval_loader: DataLoader):\n",
    "        epoch_bar = tqdm(range(epochs), desc=f'Fit ', leave=True)\n",
    "        for epoch in epoch_bar:\n",
    "             # Вызов функции обучения и получение средней потери на тренировочных данных\n",
    "            train_avg_loss = self.train(train_loader)\n",
    "            # Вызов функции оценки и получение средней потери на валидационных данных\n",
    "            eval_avg_loss = self.eval(eval_loader)\n",
    "            \n",
    "            # Обновление прогресс-бара с текущей эпохой и значениями потерь\n",
    "            epoch_bar.set_postfix({\n",
    "                'Epoch': epoch,\n",
    "                'Train Loss': f\"{train_avg_loss:.4f}\",\n",
    "                'Eval Loss': f\"{eval_avg_loss:.4f}\"\n",
    "            })\n",
    "        \n",
    "    def calculate_special_eval(self, eval_loader: DataLoader, max_length, temperature):\n",
    "        if self.special_eval and self.evaluator:\n",
    "            self.model.eval()\n",
    "            eval_bar = tqdm(eval_loader, desc=f'Special evaluate', leave=True)\n",
    "            hypotheses = []\n",
    "            references = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in eval_bar:\n",
    "                    input_ids = batch['input_ids'].to(self.device)\n",
    "                    attention_mask = batch['attention_mask'].to(self.device)\n",
    "                    target_ids = batch['target_ids'].to(self.device)\n",
    "                    type_ids = batch['type_ids'].to(self.device)\n",
    "                    \n",
    "                    hypotheses += self._generate_text_sampling(input_ids, attention_mask, type_ids, max_length, temperature)\n",
    "                    references += self.decode_tensor(target_ids)\n",
    "            self.evaluator.evaluate(hypotheses=hypotheses, references=references)\n",
    "        \n",
    "    def generate_text_sampling(self, text, type_id, max_length=25, temperature=0.9):        \n",
    "        # Токенизация входного текста\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        input_ids = inputs['input_ids'].to(self.device)\n",
    "        attention_mask = inputs['attention_mask'].to(self.device)\n",
    "        type_ids = torch.tensor([type_id]).to(self.device)\n",
    "        \n",
    "        return self._generate_text_sampling(input_ids, attention_mask, type_ids, max_length, temperature)\n",
    "    \n",
    "    def _generate_text_sampling(self, input_ids, attention_mask, type_ids, max_length=25, temperature=0.9):\n",
    "        self.model.eval() \n",
    "        generated_sequence = input_ids   \n",
    "        \n",
    "        # Начальная длина входных данных\n",
    "        start_gen_index = input_ids.size(1) \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_length):\n",
    "                outputs = self.model(input_ids=generated_sequence, attention_mask=attention_mask, type_ids=type_ids)\n",
    "                logits = outputs[:, -1, :]                \n",
    "                # Применяем температуру для управления случайностью выборки\n",
    "                logits = logits / temperature\n",
    "                probabilities = F.softmax(logits, dim=-1)\n",
    "                next_token_id = torch.multinomial(probabilities, num_samples=1)                \n",
    "                generated_sequence = torch.cat((generated_sequence, next_token_id), dim=-1)\n",
    "                \n",
    "                # Обновление attention_mask\n",
    "                attention_mask = torch.cat([attention_mask, torch.ones((attention_mask.size(0), 1), device=self.device)], dim=1)\n",
    "                \n",
    "                # if next_token_id.item() == self.tokenizer.eos_token_id:\n",
    "                #     break\n",
    "        # Возвращаем только сгенерированную часть\n",
    "        generated_part = generated_sequence[:, start_gen_index:]\n",
    "        return self.decode_tensor(generated_part)\n",
    "    \n",
    "    def decode_tensor(self, sequences: Tensor):\n",
    "        decoded_texts = []\n",
    "        for sequence in sequences:\n",
    "            decoded_text = self.tokenizer.decode(sequence, skip_special_tokens=True)\n",
    "            decoded_texts.append(decoded_text)\n",
    "        return decoded_texts\n",
    "\n",
    "        # return self.tokenizer.decode(sequence.squeeze(), skip_special_tokens=True)\n",
    "\n",
    "    def plot_main_metrics(self, imgs_path):\n",
    "        epochs_range = range(1, len(self.val_losses) + 1)\n",
    "        fig = plt.figure(figsize=(15, 6))  # Устанавливаем размер фигуры\n",
    "        \n",
    "        ax11 = plt.subplot()\n",
    "        ax11.plot(epochs_range, self.train_losses, label='Train loss', color='tab:red')\n",
    "        ax11.plot(epochs_range, self.val_losses, label='Evaluate loss', color='tab:blue')\n",
    "        ax11.set_title('Losses over Epochs')\n",
    "        ax11.set_xlabel('Epochs')\n",
    "        ax11.set_ylabel('Loss')\n",
    "        # ax11.tick_params(axis='y', labelcolor='tab:red')\n",
    "        ax11.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        ax11.legend(loc='upper right')     \n",
    "\n",
    "        fig.tight_layout()  # Убедимся, что макет не нарушен\n",
    "        save_plt_img(imgs_path, \"train_metrics\")  # extra code\n",
    "        plt.show()\n",
    "            \n",
    "    def freeze_layers(self, num_trainable_blocks=2):        \n",
    "        total_blocks = len(self.model.gpt2.h)  # h - это список всех блоков трансформера в модели GPT-2\n",
    "\n",
    "        # Заморозка слоёв в начальных блоках\n",
    "        for i, block in enumerate(self.model.gpt2.h):\n",
    "            if i < total_blocks - num_trainable_blocks:\n",
    "                for param in block.parameters():\n",
    "                    param.requires_grad = False\n",
    "            else:\n",
    "                for param in block.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        # # Если у вас есть другие специфические слои, которые нужно обучать, размораживаем их\n",
    "        # for param in model.combined_linear.parameters():\n",
    "        #     param.requires_grad = True\n",
    "    \n",
    "    def print_freezed_layers(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            print(f\"{name} is trainable: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "\n",
    "class TrainingManager:\n",
    "    def __init__(self, \n",
    "        dataframe: pd.DataFrame,\n",
    "        categorical_encoder: CategoricalLabelEncoder,\n",
    "        config: Config,\n",
    "        data_path: Path=DATA_PATH,\n",
    "        imgs_path: Path=IMAGES_PATH \n",
    "    ):\n",
    "        \n",
    "        self.uniq_name = config.uniq_name\n",
    "        self.data_path = data_path \n",
    "        self.imgs_path = imgs_path    \n",
    "        self.dataframe = dataframe\n",
    "        self.categorical_encoder = categorical_encoder\n",
    "                \n",
    "        self.config = config\n",
    "        \n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(config.model_name)\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # Разбиение данных на обучающую и тестовую выборки\n",
    "        train_data, eval_data = train_test_split(\n",
    "            self.dataframe[['type_problem', 'source', 'target']], test_size=0.1\n",
    "        )\n",
    "\n",
    "        # Создание объектов Dataset\n",
    "        train_dataset = CustomDataset(dataframe=train_data, tokenizer=self.tokenizer, max_length=config.max_length)\n",
    "        eval_dataset = CustomDataset(dataframe=eval_data, tokenizer=self.tokenizer, max_length=config.max_length)\n",
    "\n",
    "        self.train_dataloader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=config.batch_size, \n",
    "            shuffle=True\n",
    "        )\n",
    "        self.eval_dataloader = DataLoader(\n",
    "            eval_dataset, \n",
    "            batch_size=config.batch_size, \n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        self.model = CustomGPT2Model(\n",
    "            pretrained_model_name=config.model_name,\n",
    "            num_message_types=len(self.categorical_encoder.get_classes('type_problem')),\n",
    "            data_path=self.data_path\n",
    "        )\n",
    "        \n",
    "        evaluator = Evaluator(\n",
    "            self.tokenizer \n",
    "        )\n",
    "        \n",
    "        self.trainer = Trainer(\n",
    "            model=self.model,\n",
    "            evaluator=evaluator,\n",
    "            tokenizer=self.tokenizer,\n",
    "            learning_rate=config.learning_rate,\n",
    "            device=config.device,\n",
    "            imgs_path=self.imgs_path,\n",
    "            config=config   \n",
    "        )  \n",
    "    \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Запуск процесса обучения.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.trainer.fit(self.config.num_epochs, self.train_dataloader, self.eval_dataloader)\n",
    "        self.trainer.plot_main_metrics(self.imgs_path)\n",
    "        # self.trainer.evaluator.plot_metrics(self.imgs_path)\n",
    "        \n",
    "    def generate_text_sampling(self, text, type_id, max_length=25, temperature=0.9):\n",
    "        return self.trainer.generate_text_sampling(text, type_id, max_length, temperature)[0]\n",
    "\n",
    "\n",
    "    # def save(self):\n",
    "    #     self._save_model()\n",
    "    #     self._save_standard_scalar()\n",
    " \n",
    "    # def load(self):\n",
    "    #     self._load_model()\n",
    "    #     self._load_standard_scalar()\n",
    "    \n",
    "    # def _save_model(self):\n",
    "    #     \"\"\"\n",
    "    #     Сохранение обученной модели.        \n",
    "    #     \"\"\"\n",
    "    #     self.trainer.save_model(self.data_path+self.uniq_name+'_model_weight.pth')\n",
    "        \n",
    "    # def _load_model(self):\n",
    "    #     \"\"\"\n",
    "    #     Загрузка обученной модели.        \n",
    "    #     \"\"\"\n",
    "    #     self.trainer = Trainer.load_model(self.data_path+self.uniq_name+'_model_weight.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dataframe = work_dataframe[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "config.learning_rate = 1e-3\n",
    "config.num_epochs = 5\n",
    "config.max_length = 128\n",
    "config.temperature = 0.9\n",
    "config.batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список категорий в 'categoria': ['Благодарности' 'Комментарии' 'Критика власти' 'Неопределенное сообщение'\n",
      " 'Ответы' 'Повторная жалоба' 'Предложение/инициатива/идея'\n",
      " 'Просьба проинформировать' 'Семьи военнослужащих' 'Соболезнования'\n",
      " 'Устранение проблемы']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\NLP_course\\.venv\\lib\\site-packages\\transformers\\optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_manager = TrainingManager(\n",
    "    work_dataframe,\n",
    "    datafarme_encoders,\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d54194b4324a2da0e00e21dea8840a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fit :   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079706c243dd4753b8da02bde398f06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[397], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtraining_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[393], line 73\u001b[0m, in \u001b[0;36mTrainingManager.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    Запуск процесса обучения.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mplot_main_metrics(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs_path)\n",
      "Cell \u001b[1;32mIn[392], line 102\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, epochs, train_loader, eval_loader)\u001b[0m\n\u001b[0;32m     99\u001b[0m epoch_bar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFit \u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m epoch_bar:\n\u001b[0;32m    101\u001b[0m      \u001b[38;5;66;03m# Вызов функции обучения и получение средней потери на тренировочных данных\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     train_avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# Вызов функции оценки и получение средней потери на валидационных данных\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     eval_avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(eval_loader)\n",
      "Cell \u001b[1;32mIn[392], line 60\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, train_loader)\u001b[0m\n\u001b[0;32m     54\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(\n\u001b[0;32m     55\u001b[0m     logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgpt2\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size),\n\u001b[0;32m     56\u001b[0m     target_ids\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 60\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     63\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\Projects\\NLP_course\\.venv\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\NLP_course\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_manager.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предикт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>type_problem</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1558</td>\n",
       "      <td>10</td>\n",
       "      <td>Андрей Юрьевич! Доброго времени суток.Село Кос...</td>\n",
       "      <td>Добрый день, Ваше обращение направлено специал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2678</td>\n",
       "      <td>10</td>\n",
       "      <td>Всем добрый вечер.\\n\\nПосле снятия гипса со сл...</td>\n",
       "      <td>Добрый день. Ваше обращение передано в работу.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2745</td>\n",
       "      <td>10</td>\n",
       "      <td>Розыгрышей я не видела \\nГорячих напитков не б...</td>\n",
       "      <td>[id59389450|Татьяна], Добрый день! Для гостей,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1097</td>\n",
       "      <td>10</td>\n",
       "      <td>У нас в Ликино-Дулëво проехать попробовали. Эт...</td>\n",
       "      <td>[id569706568|Сергей Иконников]\\nЗдравствуйте! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>723</td>\n",
       "      <td>10</td>\n",
       "      <td>Андрей Юрьевич, просим разобраться в ситуации!...</td>\n",
       "      <td>[id39192224|Ольга Руденко] Добрый день. Измене...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  type_problem                                             source  \\\n",
       "0   1558            10  Андрей Юрьевич! Доброго времени суток.Село Кос...   \n",
       "1   2678            10  Всем добрый вечер.\\n\\nПосле снятия гипса со сл...   \n",
       "2   2745            10  Розыгрышей я не видела \\nГорячих напитков не б...   \n",
       "3   1097            10  У нас в Ликино-Дулëво проехать попробовали. Эт...   \n",
       "4    723            10  Андрей Юрьевич, просим разобраться в ситуации!...   \n",
       "\n",
       "                                              target  \n",
       "0  Добрый день, Ваше обращение направлено специал...  \n",
       "1     Добрый день. Ваше обращение передано в работу.  \n",
       "2  [id59389450|Татьяна], Добрый день! Для гостей,...  \n",
       "3  [id569706568|Сергей Иконников]\\nЗдравствуйте! ...  \n",
       "4  [id39192224|Ольга Руденко] Добрый день. Измене...  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data: pd.DataFrame = training_manager.eval_dataloader.dataset.dataframe\n",
    "testing_data = testing_data.reset_index()\n",
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Устранение проблемы']\n",
      "Source -  Андрей Юрьевич! Доброго времени суток.Село Костино Дмитровский городской округ,    частный сектор обслуживание территориальным отделом номер 6  Сергеем Колковым. У нас проживают семьи с детьми. Дорогу не чистят уже 2 день, ещё  дорога очень узкая мы очень просим прислать нам грейдер потому что трактор не справляется уже с такой нагрузкой,снега очень много. А дорогу постоянно переметает с поля. Как детям пробираться в школу по заметённой дороге? Пожалуйста примите меры. Спасибо.56.318002, 37.716737 координаты территории\n",
      "Target -  Добрый день, Ваше обращение направлено специалистам, мы вернёмся позже с ответом, как только получим информацию.\n",
      "С Уважением, МЦУР Дмитровского г. о.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "type_message = testing_data['type_problem'][0]\n",
    "source = testing_data['source'][0]\n",
    "target = testing_data['target'][0]\n",
    "\n",
    "print(datafarme_encoders.decode('type_problem', type_message))\n",
    "\n",
    "print('Source - ', source)\n",
    "print('Target - ', target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "оль. грим49527 поможет направленоНам д позже г. МО.os\n"
     ]
    }
   ],
   "source": [
    "print(training_manager.generate_text_sampling(source, type_message, max_length=16, temperature=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выполнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
